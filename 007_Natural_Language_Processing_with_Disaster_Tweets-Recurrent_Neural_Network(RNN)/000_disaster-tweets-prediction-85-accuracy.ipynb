{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### <p style=\"background-color: #EDE7F6;color:#6600ff;display: inline-block;padding:.6rem;border-radius:.5rem\">Import libraries</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-13T07:30:28.70481Z",
     "iopub.status.busy": "2024-05-13T07:30:28.704154Z",
     "iopub.status.idle": "2024-05-13T07:30:33.963491Z",
     "shell.execute_reply": "2024-05-13T07:30:33.962448Z",
     "shell.execute_reply.started": "2024-05-13T07:30:28.704777Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "import tensorflow as tf\n",
    "import keras_nlp\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\" \n",
    "\n",
    "import keras\n",
    "import keras_nlp\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### <p style=\"background-color: #EDE7F6;color:#6600ff;display: inline-block;padding:.6rem;border-radius:.5rem\">Settings</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_colwidth = 1000\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T07:33:40.105539Z",
     "iopub.status.busy": "2024-05-13T07:33:40.104466Z",
     "iopub.status.idle": "2024-05-13T07:33:40.109941Z",
     "shell.execute_reply": "2024-05-13T07:33:40.108963Z",
     "shell.execute_reply.started": "2024-05-13T07:33:40.10548Z"
    }
   },
   "outputs": [],
   "source": [
    "model_type=\"distil_bert_base_en_uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### <p style=\"background-color: #EDE7F6;color:#6600ff;display: inline-block;padding:.6rem;border-radius:.5rem\">Import data files</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T07:33:34.525824Z",
     "iopub.status.busy": "2024-05-13T07:33:34.524683Z",
     "iopub.status.idle": "2024-05-13T07:33:34.564248Z",
     "shell.execute_reply": "2024-05-13T07:33:34.563294Z",
     "shell.execute_reply.started": "2024-05-13T07:33:34.525788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_path = \"train.csv\"\n",
    "train_data = pd.read_csv(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"background-color: #EDE7F6; color: #6600ff;margin:0; display:inline-block;padding:.6rem;border-radius:.25rem;\">MODEL ENGINEERING</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T07:33:46.907511Z",
     "iopub.status.busy": "2024-05-13T07:33:46.906628Z",
     "iopub.status.idle": "2024-05-13T07:33:47.42999Z",
     "shell.execute_reply": "2024-05-13T07:33:47.42895Z",
     "shell.execute_reply.started": "2024-05-13T07:33:46.907476Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split data into training and test sets (80% train, 20% test)\n",
    "train_data, test_data = train_test_split(train_data, test_size=0.1, random_state=42)\n",
    "\n",
    "# Define a function to parse the DataFrame\n",
    "def parse_dataframe(df):\n",
    "    # Return features (text review) and labels (sentiment label)\n",
    "    return df[\"text\"].values, df[\"target\"].values\n",
    "\n",
    "# Convert training and test data to TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(parse_dataframe(train_data)).batch(32)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(parse_dataframe(test_data)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1242</td>\n",
       "      <td>blood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Omron HEM-712C Automatic Blood Pressure Monito...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7603</th>\n",
       "      <td>10862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Officials say a quarantine is in place at an A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>10409</td>\n",
       "      <td>whirlwind</td>\n",
       "      <td>Stamford &amp; Cork (&amp; Shropshire)</td>\n",
       "      <td>I moved to England five years ago today. What ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id    keyword                        location  \\\n",
       "860    1242      blood                             NaN   \n",
       "7603  10862        NaN                             NaN   \n",
       "7270  10409  whirlwind  Stamford & Cork (& Shropshire)   \n",
       "\n",
       "                                                   text  target  \n",
       "860   Omron HEM-712C Automatic Blood Pressure Monito...       0  \n",
       "7603  Officials say a quarantine is in place at an A...       1  \n",
       "7270  I moved to England five years ago today. What ...       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-05-13T07:33:52.569347Z",
     "iopub.status.busy": "2024-05-13T07:33:52.568339Z",
     "iopub.status.idle": "2024-05-13T07:34:00.886544Z",
     "shell.execute_reply": "2024-05-13T07:34:00.88566Z",
     "shell.execute_reply.started": "2024-05-13T07:33:52.56931Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras_nlp' has no attribute 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m keras_nlp\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mDistilBertTokenizer\u001b[38;5;241m.\u001b[39mfrom_preset(model_type)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras_nlp' has no attribute 'models'"
     ]
    }
   ],
   "source": [
    "tokenizer = keras_nlp.models.DistilBertTokenizer.from_preset(model_type)\n",
    "# backbone = keras_nlp.models.DistilBertBackbone.from_preset(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T07:35:50.886773Z",
     "iopub.status.busy": "2024-05-13T07:35:50.886023Z",
     "iopub.status.idle": "2024-05-13T07:35:52.293918Z",
     "shell.execute_reply": "2024-05-13T07:35:52.292833Z",
     "shell.execute_reply.started": "2024-05-13T07:35:50.886739Z"
    }
   },
   "outputs": [],
   "source": [
    "packer = keras_nlp.layers.MultiSegmentPacker(\n",
    "    start_value=tokenizer.cls_token_id,\n",
    "    end_value=tokenizer.sep_token_id,\n",
    "    pad_value=tokenizer.pad_token_id,\n",
    "    sequence_length=500\n",
    ")\n",
    "\n",
    "def preprocess(x, y):\n",
    "    token_ids, _ = packer(tokenizer(x))\n",
    "    x = {\n",
    "        \"token_ids\": token_ids,\n",
    "        \"padding_mask\": token_ids != tokenizer.pad_token_id,\n",
    "    }\n",
    "    return x, y\n",
    "\n",
    "train_ds = train_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = test_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T07:34:13.701435Z",
     "iopub.status.busy": "2024-05-13T07:34:13.700297Z",
     "iopub.status.idle": "2024-05-13T07:34:13.707357Z",
     "shell.execute_reply": "2024-05-13T07:34:13.706256Z",
     "shell.execute_reply.started": "2024-05-13T07:34:13.7014Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=3, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T07:35:59.662689Z",
     "iopub.status.busy": "2024-05-13T07:35:59.662257Z",
     "iopub.status.idle": "2024-05-13T07:43:15.661144Z",
     "shell.execute_reply": "2024-05-13T07:43:15.660264Z",
     "shell.execute_reply.started": "2024-05-13T07:35:59.66266Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = backbone.input\n",
    "outputs = backbone(inputs)[:, 0, :]\n",
    "#outputs = keras.layers.Dense(2028,activation='relu')(outputs)\n",
    "outputs = keras.layers.Dense(1024,activation='relu')(outputs)\n",
    "outputs = keras.layers.Dense(512,activation='relu')(outputs)\n",
    "outputs = keras.layers.Dense(256, activation='relu')(outputs)\n",
    "outputs = keras.layers.Dense(128,activation='relu')(outputs)\n",
    "\n",
    "outputs = keras.layers.Dropout(0.1)(outputs)\n",
    "\n",
    "outputs = keras.layers.Dense(2)(outputs)\n",
    "    \n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(1e-5),\n",
    "     metrics= [\"accuracy\"],\n",
    "    jit_compile=True,\n",
    "    \n",
    ")\n",
    "\n",
    "history=model.fit(train_ds, validation_data=val_ds,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T07:44:26.031783Z",
     "iopub.status.busy": "2024-05-13T07:44:26.031061Z",
     "iopub.status.idle": "2024-05-13T07:44:26.363821Z",
     "shell.execute_reply": "2024-05-13T07:44:26.362676Z",
     "shell.execute_reply.started": "2024-05-13T07:44:26.031745Z"
    }
   },
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot();\n",
    "print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T07:44:35.790849Z",
     "iopub.status.busy": "2024-05-13T07:44:35.789974Z",
     "iopub.status.idle": "2024-05-13T07:44:35.818035Z",
     "shell.execute_reply": "2024-05-13T07:44:35.817016Z",
     "shell.execute_reply.started": "2024-05-13T07:44:35.790812Z"
    }
   },
   "outputs": [],
   "source": [
    "# reading train data\n",
    "test_data_path = \"/kaggle/input/nlp-getting-started/test.csv\"\n",
    "\n",
    "# Load data from CSV file into a DataFrame\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "test_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T07:44:47.372873Z",
     "iopub.status.busy": "2024-05-13T07:44:47.37191Z",
     "iopub.status.idle": "2024-05-13T07:44:48.113043Z",
     "shell.execute_reply": "2024-05-13T07:44:48.112219Z",
     "shell.execute_reply.started": "2024-05-13T07:44:47.37283Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to parse the DataFrame\n",
    "def parse_dataframe(df):\n",
    "    # Return only features (text review)\n",
    "    return df[\"text\"].values\n",
    "\n",
    "# Convert test data to TensorFlow dataset\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(parse_dataframe(test_data)).batch(28)\n",
    "\n",
    "# Define the preprocess function\n",
    "def preprocess(x):\n",
    "    token_ids, _ = packer(tokenizer(x))\n",
    "    x = {\n",
    "        \"token_ids\": token_ids,\n",
    "        \"padding_mask\": token_ids != tokenizer.pad_token_id,\n",
    "    }\n",
    "    return x\n",
    "\n",
    "# Map the preprocess function to the test dataset\n",
    "test_ds = test_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_ds = tf.data.Dataset.from_tensor_slices((test_data[\"text\"]).values).batch(28)\n",
    "#test_ids = tf.data.Dataset.from_tensor_slices((test_data[\"id\"]).values).batch(28)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T07:44:59.435036Z",
     "iopub.status.busy": "2024-05-13T07:44:59.434647Z",
     "iopub.status.idle": "2024-05-13T07:44:59.452885Z",
     "shell.execute_reply": "2024-05-13T07:44:59.45192Z",
     "shell.execute_reply.started": "2024-05-13T07:44:59.435007Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T07:45:05.003262Z",
     "iopub.status.busy": "2024-05-13T07:45:05.002852Z",
     "iopub.status.idle": "2024-05-13T07:45:33.74524Z",
     "shell.execute_reply": "2024-05-13T07:45:33.744247Z",
     "shell.execute_reply.started": "2024-05-13T07:45:05.003228Z"
    }
   },
   "outputs": [],
   "source": [
    "#predictions = model.predict(test_ds)\n",
    "sample_submission[\"target\"] = np.argmax( model.predict(test_ds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T07:45:45.699853Z",
     "iopub.status.busy": "2024-05-13T07:45:45.699126Z",
     "iopub.status.idle": "2024-05-13T07:45:45.708929Z",
     "shell.execute_reply": "2024-05-13T07:45:45.707848Z",
     "shell.execute_reply.started": "2024-05-13T07:45:45.699822Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T07:45:51.844317Z",
     "iopub.status.busy": "2024-05-13T07:45:51.843612Z",
     "iopub.status.idle": "2024-05-13T07:45:51.86207Z",
     "shell.execute_reply": "2024-05-13T07:45:51.861114Z",
     "shell.execute_reply.started": "2024-05-13T07:45:51.84428Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_submission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T07:45:59.900703Z",
     "iopub.status.busy": "2024-05-13T07:45:59.899943Z",
     "iopub.status.idle": "2024-05-13T07:45:59.910508Z",
     "shell.execute_reply": "2024-05-13T07:45:59.909551Z",
     "shell.execute_reply.started": "2024-05-13T07:45:59.900669Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 869809,
     "sourceId": 17777,
     "sourceType": "competition"
    },
    {
     "modelInstanceId": 4685,
     "sourceId": 6064,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 4689,
     "sourceId": 6068,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
