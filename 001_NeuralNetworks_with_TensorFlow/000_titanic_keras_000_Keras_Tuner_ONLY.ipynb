{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### <p style=\"background-color: #EDE7F6;color:#6600ff;display: inline-block;padding:.6rem;border-radius:.5rem\">Import libraries</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T18:58:32.042495Z",
     "start_time": "2024-05-27T18:58:27.277614Z"
    },
    "execution": {
     "iopub.status.busy": "2024-05-28T12:27:43.120296Z",
     "iopub.status.idle": "2024-05-28T12:27:55.296694Z",
     "shell.execute_reply": "2024-05-28T12:27:55.295933Z",
     "shell.execute_reply.started": "2024-05-28T12:27:43.120593Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### <p style=\"background-color: #EDE7F6;color:#6600ff;display: inline-block;padding:.6rem;border-radius:.5rem\">Settings</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_colwidth = 1000\n",
    "# pd.options.display.precision = 5\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### <p style=\"background-color: #EDE7F6;color:#6600ff;display: inline-block;padding:.6rem;border-radius:.5rem\">Import data files</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T18:58:32.060068Z",
     "start_time": "2024-05-27T18:58:32.043514Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-28T12:43:44.910286Z",
     "iopub.status.busy": "2024-05-28T12:43:44.909922Z",
     "iopub.status.idle": "2024-05-28T12:43:44.924118Z",
     "shell.execute_reply": "2024-05-28T12:43:44.923138Z",
     "shell.execute_reply.started": "2024-05-28T12:43:44.910258Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"background-color: #EDE7F6; color: #6600ff;margin:0; display:inline-block;padding:.6rem;border-radius:.25rem;\">I.DATA PREPARATION</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <p style=\"background-color: #EDE7F6; color: #6600ff;margin:0; display:inline-block;padding:.6rem;border-radius:.25rem;\">A.EDA ( Exploratory Data Analysis)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### <p style=\"background-color: #EDE7F6;color:#6600ff;display: inline-block;padding:.6rem;border-radius:.5rem\">A1.Reading Data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.00</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.00</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                      Name  \\\n",
       "886          887         0       2                     Montvila, Rev. Juozas   \n",
       "887          888         1       1              Graham, Miss. Margaret Edith   \n",
       "888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n",
       "889          890         1       1                     Behr, Mr. Karl Howell   \n",
       "890          891         0       3                       Dooley, Mr. Patrick   \n",
       "\n",
       "        Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked  \n",
       "886    male  27.0      0      0      211536  13.00   NaN        S  \n",
       "887  female  19.0      0      0      112053  30.00   B42        S  \n",
       "888  female   NaN      1      2  W./C. 6607  23.45   NaN        S  \n",
       "889    male  26.0      0      0      111369  30.00  C148        C  \n",
       "890    male  32.0      0      0      370376   7.75   NaN        Q  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    549\n",
       "1    342\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surv = train['Survived'].value_counts()\n",
    "surv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### <p style=\"background-color: #EDE7F6;color:#6600ff;display: inline-block;padding:.6rem;border-radius:.5rem\">A2.Data Size</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### <p style=\"background-color: #EDE7F6;color:#6600ff;display: inline-block;padding:.6rem;border-radius:.5rem\">A3.Data Types</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### <p style=\"background-color: #EDE7F6;color:#6600ff;display: inline-block;padding:.6rem;border-radius:.5rem\">A4.Summary Statistics</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>735</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Troupiansky, Mr. Moses Aaron</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>233639</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Carter, Rev. Ernest Courtenay</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>244252</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>373</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Beavan, Mr. William Thomas</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>323951</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Woolner, Mr. Hugh</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19947</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>C52</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>381</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bidois, Miss. Rosalie</td>\n",
       "      <td>female</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17757</td>\n",
       "      <td>227.5250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>362</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>del Carlo, Mr. Sebastiano</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SC/PARIS 2167</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>472</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Cacic, Mr. Luka</td>\n",
       "      <td>male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315089</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Master. Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>351</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Odahl, Mr. Nils Martin</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7267</td>\n",
       "      <td>9.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>439</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Mark</td>\n",
       "      <td>male</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass                           Name     Sex   Age  \\\n",
       "0          735         0       2   Troupiansky, Mr. Moses Aaron    male  23.0   \n",
       "1          250         0       2  Carter, Rev. Ernest Courtenay    male  54.0   \n",
       "2          373         0       3     Beavan, Mr. William Thomas    male  19.0   \n",
       "3           56         1       1              Woolner, Mr. Hugh    male   NaN   \n",
       "4          381         1       1          Bidois, Miss. Rosalie  female  42.0   \n",
       "5          362         0       2      del Carlo, Mr. Sebastiano    male  29.0   \n",
       "6          472         0       3                Cacic, Mr. Luka    male  38.0   \n",
       "7           17         0       3           Rice, Master. Eugene    male   2.0   \n",
       "8          351         0       3         Odahl, Mr. Nils Martin    male  23.0   \n",
       "9          439         0       1              Fortune, Mr. Mark    male  64.0   \n",
       "\n",
       "   SibSp  Parch         Ticket      Fare        Cabin Embarked  \n",
       "0      0      0         233639   13.0000          NaN        S  \n",
       "1      1      0         244252   26.0000          NaN        S  \n",
       "2      0      0         323951    8.0500          NaN        S  \n",
       "3      0      0          19947   35.5000          C52        S  \n",
       "4      0      0       PC 17757  227.5250          NaN        C  \n",
       "5      1      0  SC/PARIS 2167   27.7208          NaN        C  \n",
       "6      0      0         315089    8.6625          NaN        S  \n",
       "7      4      1         382652   29.1250          NaN        Q  \n",
       "8      0      0           7267    9.2250          NaN        S  \n",
       "9      1      4          19950  263.0000  C23 C25 C27        S  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <p style=\"background-color: #EDE7F6; color: #6600ff;margin:0; display:inline-block;padding:.6rem;border-radius:.25rem;\">B.Data Pre-processing</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### <p style=\"background-color: #EDE7F6;color:#6600ff;display: inline-block;padding:.6rem;border-radius:.5rem\">B1.Missing Values</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin          687\n",
       "Age            177\n",
       "Embarked         2\n",
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan Values in train data:\n",
      "Cabin          77.10438\n",
      "Age            19.86532\n",
      "Embarked        0.22447\n",
      "PassengerId     0.00000\n",
      "Survived        0.00000\n",
      "Pclass          0.00000\n",
      "Name            0.00000\n",
      "Sex             0.00000\n",
      "SibSp           0.00000\n",
      "Parch           0.00000\n",
      "Ticket          0.00000\n",
      "Fare            0.00000\n",
      "dtype: float64\n",
      "Nan Values in test data:\n",
      "Cabin          78.22967\n",
      "Age            20.57416\n",
      "Fare            0.23923\n",
      "PassengerId     0.00000\n",
      "Pclass          0.00000\n",
      "Name            0.00000\n",
      "Sex             0.00000\n",
      "SibSp           0.00000\n",
      "Parch           0.00000\n",
      "Ticket          0.00000\n",
      "Embarked        0.00000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def null_percent(df):\n",
    "    per=((df.isnull().sum()/len(df))*100).round(5)\n",
    "    per.sort_values(ascending=False,inplace =True)\n",
    "    return per\n",
    "print(\"Nan Values in train data:\")\n",
    "print(null_percent(train))\n",
    "\n",
    "print(\"Nan Values in test data:\")\n",
    "print(null_percent(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean the dataset. Will be expanded on as more cleaning is needed\n",
    "# def clean_df(df):\n",
    "    \n",
    "#     # Split the Cabin values into a A-Z and 0-9 columns\n",
    "#     df['Cabin_ABC'] = df['Cabin'].str.extract(r'([A-Za-z]+)',expand=False)\n",
    "#     df['Cabin_Num'] = df['Cabin'].str.extract(r'(\\d+)',expand=False).astype('Float64')\n",
    "\n",
    "#     # Split the Ticket values into a A-Z and 0-9 columns\n",
    "#     df['Ticket_ABC'] = df['Ticket'].str.extract('([A-Za-z]+)')\n",
    "#     df['Ticket_Num'] = df['Ticket'].str.extract('(\\d+)').astype(float)\n",
    "\n",
    "#     # Pull and transform the title from Name\n",
    "#     df['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.',expand=False)\n",
    "#     df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'],'Rare')\n",
    "#     df['Title'] = df['Title'].replace('Mlle','Miss')\n",
    "#     df['Title'] = df['Title'].replace('Ms','Miss')\n",
    "#     df['Title'] = df['Title'].replace('Mme','Mrs')\n",
    "\n",
    "#     # Pull first name\n",
    "# #     df['First_Name'] = df['Name'].str.extract(r'(^[A-Za-z]+)',expand=False)\n",
    "\n",
    "#     # Pull last name\n",
    "# #     df['Last_Name'] = df['Name'].str.extract(r',\\s*[A-Za-z]+\\.\\s*([A-Za-z]+)',expand=False)\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = clean_df(train)\n",
    "# test= clean_df(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train.drop(columns=['Name','Ticket','Cabin'])\n",
    "# test = test.drop(columns=['Name','Ticket','Cabin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### <p style=\"background-color: #EDE7F6;color:#6600ff;display: inline-block;padding:.6rem;border-radius:.5rem\">B2.Filling Nulls</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['Cabin_ABC'] = train['Cabin_ABC'].fillna('LACK')\n",
    "# train['Ticket_ABC'] = train['Ticket_ABC'].fillna('LACK')\n",
    "\n",
    "# train['Cabin_Num'] = train['Cabin_Num'].fillna(0)\n",
    "# train['Ticket_Num'] = train['Ticket_Num'].fillna(0)\n",
    "\n",
    "# train['Last_Name'] = train['Last_Name'].fillna('LACK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test['Cabin_ABC'] = test['Cabin_ABC'].fillna('LACK')\n",
    "# test['Ticket_ABC'] = test['Ticket_ABC'].fillna('LACK')\n",
    "\n",
    "# test['Cabin_Num'] = test['Cabin_Num'].fillna(0)\n",
    "# test['Ticket_Num'] = test['Ticket_Num'].fillna(0)\n",
    "\n",
    "# test['Last_Name'] = test['Last_Name'].fillna('LACK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Cabin'] = train['Cabin'].apply(lambda x: 0 if type(x) == float else 1)\n",
    "test['Cabin'] = test['Cabin'].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "train['Cabin'] = train['Cabin'].map({1:True, 0:False})\n",
    "test['Cabin'] = test['Cabin'].map({1:True, 0:False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare',\n",
       "       'Cabin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_cols = train.select_dtypes(exclude=['object', 'category'])\n",
    "numerical_cols.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "categorical_cols = train.select_dtypes(include=['object', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_empty_categorical(df):\n",
    "    for i in categorical_cols:\n",
    "        df[i].fillna(df[i].mode()[0], inplace=True)\n",
    "    return df\n",
    "\n",
    "def fill_empty_numerical(df):\n",
    "    for i in numerical_cols:\n",
    "        df[i].fillna(df[i].median(), inplace=True)  \n",
    "    return df\n",
    "\n",
    "train = fill_empty_categorical(train)\n",
    "train = fill_empty_numerical(train)\n",
    "\n",
    "test = fill_empty_categorical(test)\n",
    "test = fill_empty_numerical(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### <p style=\"background-color: #EDE7F6;color:#6600ff;display: inline-block;padding:.6rem;border-radius:.5rem\">B3.Remove Duplicates and Unnecessary Columns</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop([\"Name\"], axis=1).copy()\n",
    "test = test.drop([\"Name\"], axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### <p style=\"background-color: #EDE7F6;color:#6600ff;display: inline-block;padding:.6rem;border-radius:.5rem\">B5.Aggregate Features</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T18:58:32.591537Z",
     "start_time": "2024-05-27T18:58:32.582339Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-28T12:43:45.82243Z",
     "iopub.status.busy": "2024-05-28T12:43:45.821844Z",
     "iopub.status.idle": "2024-05-28T12:43:45.829868Z",
     "shell.execute_reply": "2024-05-28T12:43:45.828796Z",
     "shell.execute_reply.started": "2024-05-28T12:43:45.822401Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_features = train[['Pclass','Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "# train_label = train[['Survived']]\n",
    "\n",
    "# test_features = test[['Pclass','Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <p style=\"background-color: #EDE7F6; color: #6600ff;margin:0; display:inline-block;padding:.6rem;border-radius:.25rem;\">C.Data Processing</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['Survived']).copy()\n",
    "y = train['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <p style=\"background-color: #EDE7F6; color: #6600ff;margin:0; display:inline-block;padding:.6rem;border-radius:.25rem;\">C1.Get Dummies</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Pclass       891 non-null    int64  \n",
      " 2   Sex          891 non-null    object \n",
      " 3   Age          891 non-null    float64\n",
      " 4   SibSp        891 non-null    int64  \n",
      " 5   Parch        891 non-null    int64  \n",
      " 6   Fare         891 non-null    float64\n",
      " 7   Embarked     891 non-null    object \n",
      " 8   Cabin_ABC    891 non-null    object \n",
      " 9   Cabin_Num    891 non-null    Float64\n",
      " 10  Ticket_ABC   891 non-null    object \n",
      " 11  Ticket_Num   891 non-null    float64\n",
      " 12  Title        891 non-null    object \n",
      "dtypes: Float64(1), float64(3), int64(4), object(5)\n",
      "memory usage: 91.5+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sex', 'Embarked']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categorical columns with parameters less than 11\n",
    "categorical_cols = [cname for cname in X.columns if  \n",
    "                        X[cname].dtype in ['category','object'] and X[cname].nunique() <5]\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, columns=categorical_cols)\n",
    "test = pd.get_dummies(test, columns=categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <p style=\"background-color: #EDE7F6; color: #6600ff;margin:0; display:inline-block;padding:.6rem;border-radius:.25rem;\">C5.Encoding Categorical</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ticket'], dtype='object')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns = X.select_dtypes(include=['category', 'object']).columns\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "X[categorical_columns] = encoder.fit_transform(X[categorical_columns].astype(str))\n",
    "test[categorical_columns] = encoder.fit_transform(test[categorical_columns].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>675.0</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass   Age  SibSp  Parch  Ticket     Fare  Cabin  \\\n",
       "0              1       3  22.0      1      0   523.0   7.2500  False   \n",
       "1              2       1  38.0      1      0   596.0  71.2833   True   \n",
       "2              3       3  26.0      0      0   669.0   7.9250  False   \n",
       "3              4       1  35.0      1      0    49.0  53.1000   True   \n",
       "4              5       3  35.0      0      0   472.0   8.0500  False   \n",
       "..           ...     ...   ...    ...    ...     ...      ...    ...   \n",
       "886          887       2  27.0      0      0   101.0  13.0000  False   \n",
       "887          888       1  19.0      0      0    14.0  30.0000   True   \n",
       "888          889       3  28.0      1      2   675.0  23.4500  False   \n",
       "889          890       1  26.0      0      0     8.0  30.0000   True   \n",
       "890          891       3  32.0      0      0   466.0   7.7500  False   \n",
       "\n",
       "     Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         False      True       False       False        True  \n",
       "1          True     False        True       False       False  \n",
       "2          True     False       False       False        True  \n",
       "3          True     False       False       False        True  \n",
       "4         False      True       False       False        True  \n",
       "..          ...       ...         ...         ...         ...  \n",
       "886       False      True       False       False        True  \n",
       "887        True     False       False       False        True  \n",
       "888        True     False       False       False        True  \n",
       "889       False      True        True       False       False  \n",
       "890       False      True       False        True       False  \n",
       "\n",
       "[891 rows x 13 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <p style=\"background-color: #EDE7F6; color: #6600ff;margin:0; display:inline-block;padding:.6rem;border-radius:.25rem;\">C2.Normalizing - Scaling Data (optional)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MinMaxScaler doesn't reduce the effect of outliers, but it linearly scales them down into a fixed range, where the largest occurring data point corresponds to the maximum value and the smallest one corresponds to the minimum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "test = pd.DataFrame(scaler.fit_transform(test), columns=test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.769118</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.876471</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.983824</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072059</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass       Age  SibSp  Parch    Ticket      Fare  Cabin  \\\n",
       "0     0.000000     1.0  0.271174  0.125    0.0  0.769118  0.014151    0.0   \n",
       "1     0.001124     0.0  0.472229  0.125    0.0  0.876471  0.139136    1.0   \n",
       "2     0.002247     1.0  0.321438  0.000    0.0  0.983824  0.015469    0.0   \n",
       "3     0.003371     0.0  0.434531  0.125    0.0  0.072059  0.103644    1.0   \n",
       "4     0.004494     1.0  0.434531  0.000    0.0  0.694118  0.015713    0.0   \n",
       "\n",
       "   Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         0.0       1.0         0.0         0.0         1.0  \n",
       "1         1.0       0.0         1.0         0.0         0.0  \n",
       "2         1.0       0.0         0.0         0.0         1.0  \n",
       "3         1.0       0.0         0.0         0.0         1.0  \n",
       "4         0.0       1.0         0.0         0.0         1.0  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <p style=\"background-color: #EDE7F6; color: #6600ff;margin:0; display:inline-block;padding:.6rem;border-radius:.25rem;\">C8.Delete unnecessary columns</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop([\"PassengerId\"], axis=1).copy()\n",
    "test = test.drop([\"PassengerId\"], axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"background-color: #EDE7F6; color: #6600ff;margin:0; display:inline-block;padding:.6rem;border-radius:.25rem;\">II.MODEL ENGINEERING</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the training dataframe into x(features) and y (target)\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### <p style=\"background-color: #EDE7F6;color:#6600ff;display: inline-block;padding:.6rem;border-radius:.5rem\">Import libraries</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.activations import relu, sigmoid\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <p style=\"background-color: #EDE7F6; color: #6600ff;margin:0; display:inline-block;padding:.6rem;border-radius:.25rem;\">A.Model Training</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHyperModel(keras_tuner.HyperModel):\n",
    "    def build_12(self, hp):\n",
    "        image_size = hp.Int(\"image_size\", 10, 28)\n",
    "        inputs = keras.Input(shape=(image_size, image_size))\n",
    "        outputs = layers.Flatten()(inputs)\n",
    "        outputs = layers.Dense(\n",
    "            units=hp.Int(\"units\", min_value=32, max_value=512, step=32),\n",
    "            activation=\"relu\",\n",
    "        )(outputs)\n",
    "        outputs = layers.Dense(10, activation=\"softmax\")(outputs)\n",
    "        model = keras.Model(inputs, outputs)\n",
    "        model.compile(\n",
    "            optimizer=\"adam\",\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def fit(self, hp, model, x, y, validation_data=None, **kwargs):\n",
    "        if hp.Boolean(\"normalize\"):\n",
    "            x = layers.Normalization()(x)\n",
    "        image_size = hp.get(\"image_size\")\n",
    "        cropped_x = x[:, :image_size, :image_size, :]\n",
    "        if validation_data:\n",
    "            x_val, y_val = validation_data\n",
    "            cropped_x_val = x_val[:, :image_size, :image_size, :]\n",
    "            validation_data = (cropped_x_val, y_val)\n",
    "        return model.fit(\n",
    "            cropped_x,\n",
    "            y,\n",
    "            # Tune whether to shuffle the data in each epoch.\n",
    "            shuffle=hp.Boolean(\"shuffle\"),\n",
    "            validation_data=validation_data,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "\n",
    "tuner_12 = keras_tuner.RandomSearch(\n",
    "    MyHyperModel(),\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=3,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"tune_hypermodel\",\n",
    ")\n",
    "\n",
    "\n",
    "tuner_12.search(X_train, y_train, epochs=50, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_11(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1024, activation=tf.nn.relu))\n",
    "    model.add(layers.Dropout(rate=0.1))\n",
    "    model.add(layers.Dense(512, activation=tf.nn.relu))\n",
    "    model.add(layers.Dropout(rate=0.1))\n",
    "    # Tune the number of layers.\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 2)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=32, max_value=256, step=32),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\"]),\n",
    "            )\n",
    "        )\n",
    "#         model.add(layers.Dropout(rate=0.1))\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "         model.add(layers.Dropout(rate=0.1))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential_2, built=False>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model_10(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    # Tune the number of layers.\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=256, max_value=1024, step=128),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "            )\n",
    "        )\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.1))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential_2, built=False>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def call_existing_code(units, activation, dropout, lr):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(units=units, activation=activation))\n",
    "    if dropout:\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_model_9(hp):\n",
    "    units = hp.Int(\"units\", min_value=128, max_value=1024, step=128)\n",
    "    activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "    dropout = hp.Boolean(\"dropout\")\n",
    "    lr = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    # call existing model-building code with the hyperparameter values.\n",
    "    model = call_existing_code(\n",
    "        units=units, activation=activation, dropout=dropout, lr=lr\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential_2, built=False>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model_8(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            # Tune number of units.\n",
    "            units=hp.Int(\"units\", min_value=64, max_value=1024, step=64),\n",
    "            # Tune the activation function to use.\n",
    "            activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "        )\n",
    "    )\n",
    "    # Tune whether to use dropout.\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    # Define the optimizer learning rate as a hyperparameter.\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential_3, built=False>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model_7(hp):\n",
    "    model_7 = keras.Sequential()\n",
    "    model_7.add(layers.Flatten())\n",
    "    model_7.add(\n",
    "        layers.Dense(\n",
    "            # Define the hyperparameter.\n",
    "            units=hp.Int(\"units\", min_value=32, max_value=512, step=32),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "    )\n",
    "    model_7.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model_7.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model_7\n",
    "\n",
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_11 = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model_11,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=20,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 21s]\n",
      "val_accuracy: 0.8407821357250214\n",
      "\n",
      "Best val_accuracy So Far: 0.8519552946090698\n",
      "Total elapsed time: 00h 06m 56s\n"
     ]
    }
   ],
   "source": [
    "tuner_11.search(X_train, y_train, epochs=50, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │        \u001b[38;5;34m13,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">603,905</span> (2.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m603,905\u001b[0m (2.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">603,905</span> (2.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m603,905\u001b[0m (2.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = tuner_11.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in my_dir\\helloworld\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 128\n",
      "activation: relu\n",
      "dropout: True\n",
      "lr: 0.0002413710835604695\n",
      "Score: 0.8519552946090698\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 224\n",
      "activation: relu\n",
      "dropout: True\n",
      "lr: 0.0011102890456616886\n",
      "units_1: 224\n",
      "Score: 0.8491620123386383\n",
      "\n",
      "Trial 16 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 96\n",
      "activation: relu\n",
      "dropout: True\n",
      "lr: 0.0001274939524304485\n",
      "units_1: 192\n",
      "Score: 0.8491619825363159\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 96\n",
      "activation: relu\n",
      "dropout: False\n",
      "lr: 0.00017906393704515426\n",
      "units_1: 64\n",
      "Score: 0.8463687002658844\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 192\n",
      "activation: relu\n",
      "dropout: False\n",
      "lr: 0.0012688296786930507\n",
      "Score: 0.8435754179954529\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 160\n",
      "activation: relu\n",
      "dropout: True\n",
      "lr: 0.00013352633386342022\n",
      "units_1: 32\n",
      "Score: 0.8435754179954529\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 96\n",
      "activation: relu\n",
      "dropout: True\n",
      "lr: 0.0035864828051909445\n",
      "units_1: 64\n",
      "Score: 0.8435754179954529\n",
      "\n",
      "Trial 10 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 224\n",
      "activation: relu\n",
      "dropout: False\n",
      "lr: 0.0001185989603385067\n",
      "units_1: 128\n",
      "Score: 0.8435754179954529\n",
      "\n",
      "Trial 18 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 256\n",
      "activation: relu\n",
      "dropout: False\n",
      "lr: 0.00030495366065574897\n",
      "units_1: 160\n",
      "Score: 0.8435754179954529\n",
      "\n",
      "Trial 11 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 64\n",
      "activation: relu\n",
      "dropout: True\n",
      "lr: 0.009065729012187747\n",
      "units_1: 32\n",
      "Score: 0.8407821357250214\n"
     ]
    }
   ],
   "source": [
    "tuner_11.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6606 - loss: 0.6624 - val_accuracy: 0.7709 - val_loss: 0.5800 - learning_rate: 2.4137e-04\n",
      "Epoch 2/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7840 - loss: 0.5616 - val_accuracy: 0.7821 - val_loss: 0.4950 - learning_rate: 2.4137e-04\n",
      "Epoch 3/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8039 - loss: 0.4869 - val_accuracy: 0.7821 - val_loss: 0.4527 - learning_rate: 2.4137e-04\n",
      "Epoch 4/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8092 - loss: 0.4508 - val_accuracy: 0.7821 - val_loss: 0.4430 - learning_rate: 2.4137e-04\n",
      "Epoch 5/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7929 - loss: 0.4575 - val_accuracy: 0.8045 - val_loss: 0.4329 - learning_rate: 2.4137e-04\n",
      "Epoch 6/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7980 - loss: 0.4606 - val_accuracy: 0.8101 - val_loss: 0.4251 - learning_rate: 2.4137e-04\n",
      "Epoch 7/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8038 - loss: 0.4662 - val_accuracy: 0.8212 - val_loss: 0.4210 - learning_rate: 2.4137e-04\n",
      "Epoch 8/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8073 - loss: 0.4506 - val_accuracy: 0.8156 - val_loss: 0.4203 - learning_rate: 2.4137e-04\n",
      "Epoch 9/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8135 - loss: 0.4325 - val_accuracy: 0.8156 - val_loss: 0.4158 - learning_rate: 2.4137e-04\n",
      "Epoch 10/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7994 - loss: 0.4527 - val_accuracy: 0.8156 - val_loss: 0.4166 - learning_rate: 2.4137e-04\n",
      "Epoch 11/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8260 - loss: 0.4103 - val_accuracy: 0.8101 - val_loss: 0.4100 - learning_rate: 2.4137e-04\n",
      "Epoch 12/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8058 - loss: 0.4387 - val_accuracy: 0.8268 - val_loss: 0.4097 - learning_rate: 2.4137e-04\n",
      "Epoch 13/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8195 - loss: 0.4382 - val_accuracy: 0.8324 - val_loss: 0.4063 - learning_rate: 2.4137e-04\n",
      "Epoch 14/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8035 - loss: 0.4311 - val_accuracy: 0.8212 - val_loss: 0.4029 - learning_rate: 2.4137e-04\n",
      "Epoch 15/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8230 - loss: 0.4224 - val_accuracy: 0.8212 - val_loss: 0.4030 - learning_rate: 2.4137e-04\n",
      "Epoch 16/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7905 - loss: 0.4412 - val_accuracy: 0.8268 - val_loss: 0.3961 - learning_rate: 2.4137e-04\n",
      "Epoch 17/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8325 - loss: 0.4031 - val_accuracy: 0.8324 - val_loss: 0.3957 - learning_rate: 2.4137e-04\n",
      "Epoch 18/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8078 - loss: 0.4346 - val_accuracy: 0.8212 - val_loss: 0.3950 - learning_rate: 2.4137e-04\n",
      "Epoch 19/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8242 - loss: 0.4076 - val_accuracy: 0.8268 - val_loss: 0.3949 - learning_rate: 2.4137e-04\n",
      "Epoch 20/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8137 - loss: 0.4215 - val_accuracy: 0.8268 - val_loss: 0.3930 - learning_rate: 2.4137e-04\n",
      "Epoch 21/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8301 - loss: 0.4057 - val_accuracy: 0.8324 - val_loss: 0.3878 - learning_rate: 2.4137e-04\n",
      "Epoch 22/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8198 - loss: 0.4180 - val_accuracy: 0.8268 - val_loss: 0.3876 - learning_rate: 2.4137e-04\n",
      "Epoch 23/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8304 - loss: 0.3976 - val_accuracy: 0.8324 - val_loss: 0.3840 - learning_rate: 2.4137e-04\n",
      "Epoch 24/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8432 - loss: 0.3886 - val_accuracy: 0.8324 - val_loss: 0.3833 - learning_rate: 2.4137e-04\n",
      "Epoch 25/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8104 - loss: 0.4155 - val_accuracy: 0.8324 - val_loss: 0.3788 - learning_rate: 2.4137e-04\n",
      "Epoch 26/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8205 - loss: 0.4021 - val_accuracy: 0.8492 - val_loss: 0.3784 - learning_rate: 2.4137e-04\n",
      "Epoch 27/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8331 - loss: 0.3906 - val_accuracy: 0.8324 - val_loss: 0.3782 - learning_rate: 2.4137e-04\n",
      "Epoch 28/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8312 - loss: 0.3989 - val_accuracy: 0.8380 - val_loss: 0.3770 - learning_rate: 2.4137e-04\n",
      "Epoch 29/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8263 - loss: 0.3948 - val_accuracy: 0.8380 - val_loss: 0.3758 - learning_rate: 2.4137e-04\n",
      "Epoch 30/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8250 - loss: 0.3898 - val_accuracy: 0.8380 - val_loss: 0.3723 - learning_rate: 2.4137e-04\n",
      "Epoch 31/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8338 - loss: 0.3761 - val_accuracy: 0.8380 - val_loss: 0.3707 - learning_rate: 2.4137e-04\n",
      "Epoch 32/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8293 - loss: 0.3991 - val_accuracy: 0.8436 - val_loss: 0.3719 - learning_rate: 2.4137e-04\n",
      "Epoch 33/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8457 - loss: 0.3716 - val_accuracy: 0.8492 - val_loss: 0.3732 - learning_rate: 2.4137e-04\n",
      "Epoch 34/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8332 - loss: 0.3894 - val_accuracy: 0.8436 - val_loss: 0.3685 - learning_rate: 2.4137e-04\n",
      "Epoch 35/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8232 - loss: 0.4017 - val_accuracy: 0.8492 - val_loss: 0.3677 - learning_rate: 2.4137e-04\n",
      "Epoch 36/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8384 - loss: 0.3786 - val_accuracy: 0.8436 - val_loss: 0.3679 - learning_rate: 2.4137e-04\n",
      "Epoch 37/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8455 - loss: 0.3626 - val_accuracy: 0.8492 - val_loss: 0.3668 - learning_rate: 2.4137e-04\n",
      "Epoch 38/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8267 - loss: 0.3971 - val_accuracy: 0.8324 - val_loss: 0.3673 - learning_rate: 2.4137e-04\n",
      "Epoch 39/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8411 - loss: 0.3820 - val_accuracy: 0.8492 - val_loss: 0.3675 - learning_rate: 2.4137e-04\n",
      "Epoch 40/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8446 - loss: 0.3896 - val_accuracy: 0.8436 - val_loss: 0.3655 - learning_rate: 2.4137e-04\n",
      "Epoch 41/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8412 - loss: 0.3688 - val_accuracy: 0.8436 - val_loss: 0.3622 - learning_rate: 2.4137e-04\n",
      "Epoch 42/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8299 - loss: 0.3997 - val_accuracy: 0.8380 - val_loss: 0.3652 - learning_rate: 2.4137e-04\n",
      "Epoch 43/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8308 - loss: 0.3932 - val_accuracy: 0.8492 - val_loss: 0.3661 - learning_rate: 2.4137e-04\n",
      "Epoch 44/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8609 - loss: 0.3548 - val_accuracy: 0.8492 - val_loss: 0.3653 - learning_rate: 2.4137e-04\n",
      "Epoch 45/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8400 - loss: 0.3949 - val_accuracy: 0.8436 - val_loss: 0.3637 - learning_rate: 2.4137e-04\n",
      "Epoch 46/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8445 - loss: 0.3753 - val_accuracy: 0.8492 - val_loss: 0.3648 - learning_rate: 2.4137e-04\n",
      "Epoch 47/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8398 - loss: 0.3840 - val_accuracy: 0.8380 - val_loss: 0.3731 - learning_rate: 2.4137e-04\n",
      "Epoch 48/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8403 - loss: 0.3768 - val_accuracy: 0.8492 - val_loss: 0.3687 - learning_rate: 2.4137e-04\n",
      "Epoch 49/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8334 - loss: 0.3957 - val_accuracy: 0.8436 - val_loss: 0.3587 - learning_rate: 2.4137e-04\n",
      "Epoch 50/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8409 - loss: 0.3741 - val_accuracy: 0.8547 - val_loss: 0.3560 - learning_rate: 2.4137e-04\n",
      "Epoch 51/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8459 - loss: 0.3637 - val_accuracy: 0.8492 - val_loss: 0.3548 - learning_rate: 2.4137e-04\n",
      "Epoch 52/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8376 - loss: 0.3783 - val_accuracy: 0.8492 - val_loss: 0.3584 - learning_rate: 2.4137e-04\n",
      "Epoch 53/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8400 - loss: 0.3785 - val_accuracy: 0.8547 - val_loss: 0.3541 - learning_rate: 2.4137e-04\n",
      "Epoch 54/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8369 - loss: 0.3768 - val_accuracy: 0.8547 - val_loss: 0.3554 - learning_rate: 2.4137e-04\n",
      "Epoch 55/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8387 - loss: 0.3699 - val_accuracy: 0.8492 - val_loss: 0.3545 - learning_rate: 2.4137e-04\n",
      "Epoch 56/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8340 - loss: 0.3878 - val_accuracy: 0.8492 - val_loss: 0.3560 - learning_rate: 2.4137e-04\n",
      "Epoch 57/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8502 - loss: 0.3717 - val_accuracy: 0.8492 - val_loss: 0.3552 - learning_rate: 2.4137e-04\n",
      "Epoch 58/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8650 - loss: 0.3480 - val_accuracy: 0.8436 - val_loss: 0.3523 - learning_rate: 2.4137e-04\n",
      "Epoch 59/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8627 - loss: 0.3575 - val_accuracy: 0.8492 - val_loss: 0.3503 - learning_rate: 2.4137e-04\n",
      "Epoch 60/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8272 - loss: 0.3821 - val_accuracy: 0.8492 - val_loss: 0.3500 - learning_rate: 2.4137e-04\n",
      "Epoch 61/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8346 - loss: 0.3728 - val_accuracy: 0.8492 - val_loss: 0.3515 - learning_rate: 2.4137e-04\n",
      "Epoch 62/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8421 - loss: 0.3644 - val_accuracy: 0.8492 - val_loss: 0.3490 - learning_rate: 2.4137e-04\n",
      "Epoch 63/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8255 - loss: 0.3843 - val_accuracy: 0.8492 - val_loss: 0.3456 - learning_rate: 2.4137e-04\n",
      "Epoch 64/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8386 - loss: 0.3649 - val_accuracy: 0.8547 - val_loss: 0.3498 - learning_rate: 2.4137e-04\n",
      "Epoch 65/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8554 - loss: 0.3494 - val_accuracy: 0.8436 - val_loss: 0.3469 - learning_rate: 2.4137e-04\n",
      "Epoch 66/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8467 - loss: 0.3686 - val_accuracy: 0.8492 - val_loss: 0.3518 - learning_rate: 2.4137e-04\n",
      "Epoch 67/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8554 - loss: 0.3383 - val_accuracy: 0.8492 - val_loss: 0.3424 - learning_rate: 2.4137e-04\n",
      "Epoch 68/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8352 - loss: 0.3720 - val_accuracy: 0.8436 - val_loss: 0.3429 - learning_rate: 2.4137e-04\n",
      "Epoch 69/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8343 - loss: 0.3753 - val_accuracy: 0.8492 - val_loss: 0.3487 - learning_rate: 2.4137e-04\n",
      "Epoch 70/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8691 - loss: 0.3334 - val_accuracy: 0.8436 - val_loss: 0.3430 - learning_rate: 2.4137e-04\n",
      "Epoch 71/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8224 - loss: 0.4033 - val_accuracy: 0.8436 - val_loss: 0.3439 - learning_rate: 2.4137e-04\n",
      "Epoch 72/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8383 - loss: 0.3676 - val_accuracy: 0.8436 - val_loss: 0.3410 - learning_rate: 2.4137e-04\n",
      "Epoch 73/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8398 - loss: 0.3600 - val_accuracy: 0.8436 - val_loss: 0.3407 - learning_rate: 2.4137e-04\n",
      "Epoch 74/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8353 - loss: 0.3542 - val_accuracy: 0.8492 - val_loss: 0.3405 - learning_rate: 2.4137e-04\n",
      "Epoch 75/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8509 - loss: 0.3530 - val_accuracy: 0.8436 - val_loss: 0.3406 - learning_rate: 2.4137e-04\n",
      "Epoch 76/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8488 - loss: 0.3605 - val_accuracy: 0.8436 - val_loss: 0.3456 - learning_rate: 2.4137e-04\n",
      "Epoch 77/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8471 - loss: 0.3640 - val_accuracy: 0.8436 - val_loss: 0.3412 - learning_rate: 2.4137e-04\n",
      "Epoch 78/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8303 - loss: 0.3760 - val_accuracy: 0.8492 - val_loss: 0.3352 - learning_rate: 2.4137e-04\n",
      "Epoch 79/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8404 - loss: 0.3627 - val_accuracy: 0.8492 - val_loss: 0.3332 - learning_rate: 2.4137e-04\n",
      "Epoch 80/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8310 - loss: 0.3558 - val_accuracy: 0.8436 - val_loss: 0.3396 - learning_rate: 2.4137e-04\n",
      "Epoch 81/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8453 - loss: 0.3572 - val_accuracy: 0.8436 - val_loss: 0.3414 - learning_rate: 2.4137e-04\n",
      "Epoch 82/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8433 - loss: 0.3544 - val_accuracy: 0.8492 - val_loss: 0.3350 - learning_rate: 2.4137e-04\n",
      "Epoch 83/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8456 - loss: 0.3548 - val_accuracy: 0.8492 - val_loss: 0.3307 - learning_rate: 2.4137e-04\n",
      "Epoch 84/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8300 - loss: 0.3759 - val_accuracy: 0.8436 - val_loss: 0.3356 - learning_rate: 2.4137e-04\n",
      "Epoch 85/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8548 - loss: 0.3400 - val_accuracy: 0.8492 - val_loss: 0.3383 - learning_rate: 2.4137e-04\n",
      "Epoch 86/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8416 - loss: 0.3418 - val_accuracy: 0.8436 - val_loss: 0.3303 - learning_rate: 2.4137e-04\n",
      "Epoch 87/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8532 - loss: 0.3468 - val_accuracy: 0.8436 - val_loss: 0.3383 - learning_rate: 2.4137e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8522 - loss: 0.3456 - val_accuracy: 0.8436 - val_loss: 0.3321 - learning_rate: 2.4137e-04\n",
      "Epoch 89/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8424 - loss: 0.3578 - val_accuracy: 0.8436 - val_loss: 0.3293 - learning_rate: 2.4137e-04\n",
      "Epoch 90/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8381 - loss: 0.3491 - val_accuracy: 0.8436 - val_loss: 0.3306 - learning_rate: 2.4137e-04\n",
      "Epoch 91/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8588 - loss: 0.3494 - val_accuracy: 0.8436 - val_loss: 0.3310 - learning_rate: 2.4137e-04\n",
      "Epoch 92/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8447 - loss: 0.3516 - val_accuracy: 0.8492 - val_loss: 0.3265 - learning_rate: 2.4137e-04\n",
      "Epoch 93/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8273 - loss: 0.3597 - val_accuracy: 0.8436 - val_loss: 0.3302 - learning_rate: 2.4137e-04\n",
      "Epoch 94/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8250 - loss: 0.3786 - val_accuracy: 0.8492 - val_loss: 0.3259 - learning_rate: 2.4137e-04\n",
      "Epoch 95/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8432 - loss: 0.3461 - val_accuracy: 0.8436 - val_loss: 0.3244 - learning_rate: 2.4137e-04\n",
      "Epoch 96/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8492 - loss: 0.3300 - val_accuracy: 0.8436 - val_loss: 0.3247 - learning_rate: 2.4137e-04\n",
      "Epoch 97/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8545 - loss: 0.3443 - val_accuracy: 0.8492 - val_loss: 0.3290 - learning_rate: 2.4137e-04\n",
      "Epoch 98/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8490 - loss: 0.3376 - val_accuracy: 0.8436 - val_loss: 0.3191 - learning_rate: 2.4137e-04\n",
      "Epoch 99/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8468 - loss: 0.3549 - val_accuracy: 0.8436 - val_loss: 0.3225 - learning_rate: 2.4137e-04\n",
      "Epoch 100/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8625 - loss: 0.3238 - val_accuracy: 0.8436 - val_loss: 0.3246 - learning_rate: 2.4137e-04\n",
      "Epoch 101/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8287 - loss: 0.3464 - val_accuracy: 0.8492 - val_loss: 0.3217 - learning_rate: 2.4137e-04\n",
      "Epoch 102/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8463 - loss: 0.3461 - val_accuracy: 0.8436 - val_loss: 0.3244 - learning_rate: 2.4137e-04\n",
      "Epoch 103/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8625 - loss: 0.3244 - val_accuracy: 0.8603 - val_loss: 0.3202 - learning_rate: 2.4137e-04\n",
      "Epoch 104/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8454 - loss: 0.3432 - val_accuracy: 0.8492 - val_loss: 0.3190 - learning_rate: 2.4137e-04\n",
      "Epoch 105/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8517 - loss: 0.3446 - val_accuracy: 0.8436 - val_loss: 0.3192 - learning_rate: 2.4137e-04\n",
      "Epoch 106/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8483 - loss: 0.3380 - val_accuracy: 0.8492 - val_loss: 0.3158 - learning_rate: 2.4137e-04\n",
      "Epoch 107/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8588 - loss: 0.3312 - val_accuracy: 0.8436 - val_loss: 0.3177 - learning_rate: 2.4137e-04\n",
      "Epoch 108/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8427 - loss: 0.3470 - val_accuracy: 0.8436 - val_loss: 0.3182 - learning_rate: 2.4137e-04\n",
      "Epoch 109/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8506 - loss: 0.3368 - val_accuracy: 0.8715 - val_loss: 0.3135 - learning_rate: 2.4137e-04\n",
      "Epoch 110/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8604 - loss: 0.3148 - val_accuracy: 0.8492 - val_loss: 0.3158 - learning_rate: 2.4137e-04\n",
      "Epoch 111/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8445 - loss: 0.3516 - val_accuracy: 0.8436 - val_loss: 0.3168 - learning_rate: 2.4137e-04\n",
      "Epoch 112/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8529 - loss: 0.3401 - val_accuracy: 0.8659 - val_loss: 0.3139 - learning_rate: 2.4137e-04\n",
      "Epoch 113/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8531 - loss: 0.3355 - val_accuracy: 0.8492 - val_loss: 0.3115 - learning_rate: 2.4137e-04\n",
      "Epoch 114/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8596 - loss: 0.3296 - val_accuracy: 0.8659 - val_loss: 0.3155 - learning_rate: 2.4137e-04\n",
      "Epoch 115/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8532 - loss: 0.3453 - val_accuracy: 0.8659 - val_loss: 0.3121 - learning_rate: 2.4137e-04\n",
      "Epoch 116/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8472 - loss: 0.3449 - val_accuracy: 0.8547 - val_loss: 0.3066 - learning_rate: 2.4137e-04\n",
      "Epoch 117/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8604 - loss: 0.3105 - val_accuracy: 0.8492 - val_loss: 0.3128 - learning_rate: 2.4137e-04\n",
      "Epoch 118/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8782 - loss: 0.2954 - val_accuracy: 0.8492 - val_loss: 0.3060 - learning_rate: 2.4137e-04\n",
      "Epoch 119/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8547 - loss: 0.3216 - val_accuracy: 0.8603 - val_loss: 0.3028 - learning_rate: 2.4137e-04\n",
      "Epoch 120/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8776 - loss: 0.3091 - val_accuracy: 0.8436 - val_loss: 0.3096 - learning_rate: 2.4137e-04\n",
      "Epoch 121/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8558 - loss: 0.3270 - val_accuracy: 0.8659 - val_loss: 0.3051 - learning_rate: 2.4137e-04\n",
      "Epoch 122/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8584 - loss: 0.3297 - val_accuracy: 0.8659 - val_loss: 0.3010 - learning_rate: 2.4137e-04\n",
      "Epoch 123/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8425 - loss: 0.3393 - val_accuracy: 0.8603 - val_loss: 0.3018 - learning_rate: 2.4137e-04\n",
      "Epoch 124/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8664 - loss: 0.3137 - val_accuracy: 0.8492 - val_loss: 0.3116 - learning_rate: 2.4137e-04\n",
      "Epoch 125/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8435 - loss: 0.3247 - val_accuracy: 0.8659 - val_loss: 0.3051 - learning_rate: 2.4137e-04\n",
      "Epoch 126/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8423 - loss: 0.3576 - val_accuracy: 0.8380 - val_loss: 0.3156 - learning_rate: 2.4137e-04\n",
      "Epoch 127/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8568 - loss: 0.3298 - val_accuracy: 0.8492 - val_loss: 0.3052 - learning_rate: 2.4137e-04\n",
      "Epoch 128/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8517 - loss: 0.3199 - val_accuracy: 0.8827 - val_loss: 0.2975 - learning_rate: 2.4137e-04\n",
      "Epoch 129/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8486 - loss: 0.3272 - val_accuracy: 0.8436 - val_loss: 0.3084 - learning_rate: 2.4137e-04\n",
      "Epoch 130/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8423 - loss: 0.3259 - val_accuracy: 0.8547 - val_loss: 0.2984 - learning_rate: 2.4137e-04\n",
      "Epoch 131/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8509 - loss: 0.3322 - val_accuracy: 0.8827 - val_loss: 0.2982 - learning_rate: 2.4137e-04\n",
      "Epoch 132/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8419 - loss: 0.3428 - val_accuracy: 0.8715 - val_loss: 0.3008 - learning_rate: 2.4137e-04\n",
      "Epoch 133/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8715 - loss: 0.3138 - val_accuracy: 0.8492 - val_loss: 0.3034 - learning_rate: 2.4137e-04\n",
      "Epoch 134/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8534 - loss: 0.3329 - val_accuracy: 0.8771 - val_loss: 0.2950 - learning_rate: 2.4137e-04\n",
      "Epoch 135/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8498 - loss: 0.3334 - val_accuracy: 0.8883 - val_loss: 0.2873 - learning_rate: 2.4137e-04\n",
      "Epoch 136/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8495 - loss: 0.3320 - val_accuracy: 0.8659 - val_loss: 0.3013 - learning_rate: 2.4137e-04\n",
      "Epoch 137/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8631 - loss: 0.3172 - val_accuracy: 0.8715 - val_loss: 0.2974 - learning_rate: 2.4137e-04\n",
      "Epoch 138/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8776 - loss: 0.2896 - val_accuracy: 0.8492 - val_loss: 0.3078 - learning_rate: 2.4137e-04\n",
      "Epoch 139/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8557 - loss: 0.3176 - val_accuracy: 0.8827 - val_loss: 0.2992 - learning_rate: 2.4137e-04\n",
      "Epoch 140/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8675 - loss: 0.3180 - val_accuracy: 0.8547 - val_loss: 0.3101 - learning_rate: 2.4137e-04\n",
      "Epoch 141/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8631 - loss: 0.3057 - val_accuracy: 0.8771 - val_loss: 0.2987 - learning_rate: 2.4137e-04\n",
      "Epoch 142/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8651 - loss: 0.3058 - val_accuracy: 0.8436 - val_loss: 0.3030 - learning_rate: 2.4137e-04\n",
      "Epoch 143/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8538 - loss: 0.3273 - val_accuracy: 0.8827 - val_loss: 0.2886 - learning_rate: 2.4137e-04\n",
      "Epoch 144/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8623 - loss: 0.3246 - val_accuracy: 0.8547 - val_loss: 0.2965 - learning_rate: 2.4137e-04\n",
      "Epoch 145/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8544 - loss: 0.3268 - val_accuracy: 0.8492 - val_loss: 0.2974 - learning_rate: 2.4137e-04\n",
      "Epoch 146/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8668 - loss: 0.2932 - val_accuracy: 0.8827 - val_loss: 0.2877 - learning_rate: 2.4137e-04\n",
      "Epoch 147/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8644 - loss: 0.3277 - val_accuracy: 0.8659 - val_loss: 0.2880 - learning_rate: 2.4137e-04\n",
      "Epoch 148/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8705 - loss: 0.2948 - val_accuracy: 0.8492 - val_loss: 0.2951 - learning_rate: 2.4137e-04\n",
      "Epoch 149/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8458 - loss: 0.3240 - val_accuracy: 0.8715 - val_loss: 0.2909 - learning_rate: 2.4137e-04\n",
      "Epoch 150/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8658 - loss: 0.3115 - val_accuracy: 0.8827 - val_loss: 0.2860 - learning_rate: 2.4137e-04\n",
      "Epoch 151/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8636 - loss: 0.3263 - val_accuracy: 0.8771 - val_loss: 0.2871 - learning_rate: 2.4137e-04\n",
      "Epoch 152/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8574 - loss: 0.3093 - val_accuracy: 0.8715 - val_loss: 0.2876 - learning_rate: 2.4137e-04\n",
      "Epoch 153/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8627 - loss: 0.3183 - val_accuracy: 0.8492 - val_loss: 0.2958 - learning_rate: 2.4137e-04\n",
      "Epoch 154/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8558 - loss: 0.3308 - val_accuracy: 0.9050 - val_loss: 0.2850 - learning_rate: 2.4137e-04\n",
      "Epoch 155/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8734 - loss: 0.2936 - val_accuracy: 0.8492 - val_loss: 0.2905 - learning_rate: 2.4137e-04\n",
      "Epoch 156/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8677 - loss: 0.3105 - val_accuracy: 0.8827 - val_loss: 0.2807 - learning_rate: 2.4137e-04\n",
      "Epoch 157/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8659 - loss: 0.3174 - val_accuracy: 0.8771 - val_loss: 0.2855 - learning_rate: 2.4137e-04\n",
      "Epoch 158/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8580 - loss: 0.3322 - val_accuracy: 0.8715 - val_loss: 0.2887 - learning_rate: 2.4137e-04\n",
      "Epoch 159/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8659 - loss: 0.3269 - val_accuracy: 0.8603 - val_loss: 0.2812 - learning_rate: 2.4137e-04\n",
      "Epoch 160/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8514 - loss: 0.3388 - val_accuracy: 0.8547 - val_loss: 0.2943 - learning_rate: 2.4137e-04\n",
      "Epoch 161/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8459 - loss: 0.3259 - val_accuracy: 0.8827 - val_loss: 0.2831 - learning_rate: 2.4137e-04\n",
      "Epoch 162/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8710 - loss: 0.3180 - val_accuracy: 0.8715 - val_loss: 0.2830 - learning_rate: 2.4137e-04\n",
      "Epoch 163/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8665 - loss: 0.3121 - val_accuracy: 0.8492 - val_loss: 0.2885 - learning_rate: 2.4137e-04\n",
      "Epoch 164/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8781 - loss: 0.2798 - val_accuracy: 0.8939 - val_loss: 0.2826 - learning_rate: 2.4137e-04\n",
      "Epoch 165/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8688 - loss: 0.3260 - val_accuracy: 0.8547 - val_loss: 0.2890 - learning_rate: 2.4137e-04\n",
      "Epoch 166/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8587 - loss: 0.3162 - val_accuracy: 0.8994 - val_loss: 0.2805 - learning_rate: 2.4137e-04\n",
      "Epoch 167/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8782 - loss: 0.2965 - val_accuracy: 0.8659 - val_loss: 0.2793 - learning_rate: 2.4137e-04\n",
      "Epoch 168/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8781 - loss: 0.2859 - val_accuracy: 0.8883 - val_loss: 0.2756 - learning_rate: 2.4137e-04\n",
      "Epoch 169/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8560 - loss: 0.3175 - val_accuracy: 0.8939 - val_loss: 0.2763 - learning_rate: 2.4137e-04\n",
      "Epoch 170/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8700 - loss: 0.2983 - val_accuracy: 0.8883 - val_loss: 0.2747 - learning_rate: 2.4137e-04\n",
      "Epoch 171/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8705 - loss: 0.3076 - val_accuracy: 0.9050 - val_loss: 0.2757 - learning_rate: 2.4137e-04\n",
      "Epoch 172/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8548 - loss: 0.3194 - val_accuracy: 0.8827 - val_loss: 0.2755 - learning_rate: 2.4137e-04\n",
      "Epoch 173/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8735 - loss: 0.2996 - val_accuracy: 0.8883 - val_loss: 0.2760 - learning_rate: 2.4137e-04\n",
      "Epoch 174/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8815 - loss: 0.2946 - val_accuracy: 0.8715 - val_loss: 0.2806 - learning_rate: 2.4137e-04\n",
      "Epoch 175/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8628 - loss: 0.2979 - val_accuracy: 0.8939 - val_loss: 0.2803 - learning_rate: 2.4137e-04\n",
      "Epoch 176/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8769 - loss: 0.2929 - val_accuracy: 0.8827 - val_loss: 0.2755 - learning_rate: 2.4137e-04\n",
      "Epoch 177/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8864 - loss: 0.2878 - val_accuracy: 0.8827 - val_loss: 0.2758 - learning_rate: 2.4137e-04\n",
      "Epoch 178/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8769 - loss: 0.3012 - val_accuracy: 0.8939 - val_loss: 0.2750 - learning_rate: 2.4137e-04\n",
      "Epoch 179/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8621 - loss: 0.3179 - val_accuracy: 0.9050 - val_loss: 0.2728 - learning_rate: 2.4137e-04\n",
      "Epoch 180/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8642 - loss: 0.2990 - val_accuracy: 0.8939 - val_loss: 0.2706 - learning_rate: 2.4137e-04\n",
      "Epoch 181/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8482 - loss: 0.3275 - val_accuracy: 0.8883 - val_loss: 0.2687 - learning_rate: 2.4137e-04\n",
      "Epoch 182/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8794 - loss: 0.2730 - val_accuracy: 0.8939 - val_loss: 0.2726 - learning_rate: 2.4137e-04\n",
      "Epoch 183/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8703 - loss: 0.2986 - val_accuracy: 0.8827 - val_loss: 0.2769 - learning_rate: 2.4137e-04\n",
      "Epoch 184/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8774 - loss: 0.2932 - val_accuracy: 0.8939 - val_loss: 0.2724 - learning_rate: 2.4137e-04\n",
      "Epoch 185/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8860 - loss: 0.2785 - val_accuracy: 0.8771 - val_loss: 0.2783 - learning_rate: 2.4137e-04\n",
      "Epoch 186/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8801 - loss: 0.2869 - val_accuracy: 0.8939 - val_loss: 0.2651 - learning_rate: 2.4137e-04\n",
      "Epoch 187/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8651 - loss: 0.3186 - val_accuracy: 0.8827 - val_loss: 0.2780 - learning_rate: 2.4137e-04\n",
      "Epoch 188/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8780 - loss: 0.2928 - val_accuracy: 0.9050 - val_loss: 0.2786 - learning_rate: 2.4137e-04\n",
      "Epoch 189/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8702 - loss: 0.3169 - val_accuracy: 0.8994 - val_loss: 0.2718 - learning_rate: 2.4137e-04\n",
      "Epoch 190/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8715 - loss: 0.3078 - val_accuracy: 0.9050 - val_loss: 0.2642 - learning_rate: 2.4137e-04\n",
      "Epoch 191/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8761 - loss: 0.2961 - val_accuracy: 0.8939 - val_loss: 0.2738 - learning_rate: 2.4137e-04\n",
      "Epoch 192/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8673 - loss: 0.3039 - val_accuracy: 0.9050 - val_loss: 0.2629 - learning_rate: 2.4137e-04\n",
      "Epoch 193/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8782 - loss: 0.2926 - val_accuracy: 0.9106 - val_loss: 0.2634 - learning_rate: 2.4137e-04\n",
      "Epoch 194/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8842 - loss: 0.2900 - val_accuracy: 0.8939 - val_loss: 0.2651 - learning_rate: 2.4137e-04\n",
      "Epoch 195/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8662 - loss: 0.3168 - val_accuracy: 0.8994 - val_loss: 0.2634 - learning_rate: 2.4137e-04\n",
      "Epoch 196/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8787 - loss: 0.2889 - val_accuracy: 0.8994 - val_loss: 0.2642 - learning_rate: 2.4137e-04\n",
      "Epoch 197/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8861 - loss: 0.2830 - val_accuracy: 0.8939 - val_loss: 0.2716 - learning_rate: 2.4137e-04\n",
      "Epoch 198/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8792 - loss: 0.3004 - val_accuracy: 0.9106 - val_loss: 0.2613 - learning_rate: 2.4137e-04\n",
      "Epoch 199/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8875 - loss: 0.2645 - val_accuracy: 0.9050 - val_loss: 0.2552 - learning_rate: 2.4137e-04\n",
      "Epoch 200/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8672 - loss: 0.3201 - val_accuracy: 0.8715 - val_loss: 0.2651 - learning_rate: 2.4137e-04\n",
      "Epoch 201/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8599 - loss: 0.3001 - val_accuracy: 0.9162 - val_loss: 0.2591 - learning_rate: 2.4137e-04\n",
      "Epoch 202/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8858 - loss: 0.2886 - val_accuracy: 0.8883 - val_loss: 0.2639 - learning_rate: 2.4137e-04\n",
      "Epoch 203/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8822 - loss: 0.2894 - val_accuracy: 0.9050 - val_loss: 0.2601 - learning_rate: 2.4137e-04\n",
      "Epoch 204/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8767 - loss: 0.2951 - val_accuracy: 0.8994 - val_loss: 0.2687 - learning_rate: 2.4137e-04\n",
      "Epoch 205/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8825 - loss: 0.2867 - val_accuracy: 0.8939 - val_loss: 0.2687 - learning_rate: 2.4137e-04\n",
      "Epoch 206/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8776 - loss: 0.2763 - val_accuracy: 0.8994 - val_loss: 0.2602 - learning_rate: 2.4137e-04\n",
      "Epoch 207/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8811 - loss: 0.2892 - val_accuracy: 0.8883 - val_loss: 0.2724 - learning_rate: 2.4137e-04\n",
      "Epoch 208/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8764 - loss: 0.2870 - val_accuracy: 0.9106 - val_loss: 0.2585 - learning_rate: 2.4137e-04\n",
      "Epoch 209/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8887 - loss: 0.2823 - val_accuracy: 0.9162 - val_loss: 0.2570 - learning_rate: 2.4137e-04\n",
      "Epoch 210/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8878 - loss: 0.2938 - val_accuracy: 0.8883 - val_loss: 0.2638 - learning_rate: 2.4137e-04\n",
      "Epoch 211/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8740 - loss: 0.2822 - val_accuracy: 0.8994 - val_loss: 0.2591 - learning_rate: 2.4137e-04\n",
      "Epoch 212/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8749 - loss: 0.3008 - val_accuracy: 0.8939 - val_loss: 0.2615 - learning_rate: 2.4137e-04\n",
      "Epoch 213/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8814 - loss: 0.2789 - val_accuracy: 0.8994 - val_loss: 0.2603 - learning_rate: 2.4137e-04\n",
      "Epoch 214/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8753 - loss: 0.2964 - val_accuracy: 0.9162 - val_loss: 0.2564 - learning_rate: 2.4137e-04\n",
      "Epoch 215/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8964 - loss: 0.2697 - val_accuracy: 0.8994 - val_loss: 0.2594 - learning_rate: 2.4137e-04\n",
      "Epoch 216/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8665 - loss: 0.3061 - val_accuracy: 0.9162 - val_loss: 0.2579 - learning_rate: 2.4137e-04\n",
      "Epoch 217/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8715 - loss: 0.2984 - val_accuracy: 0.9050 - val_loss: 0.2556 - learning_rate: 2.4137e-04\n",
      "Epoch 218/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8741 - loss: 0.2836 - val_accuracy: 0.9162 - val_loss: 0.2539 - learning_rate: 2.4137e-04\n",
      "Epoch 219/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8632 - loss: 0.3064 - val_accuracy: 0.9162 - val_loss: 0.2519 - learning_rate: 2.4137e-04\n",
      "Epoch 220/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8706 - loss: 0.2981 - val_accuracy: 0.9050 - val_loss: 0.2543 - learning_rate: 2.4137e-04\n",
      "Epoch 221/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8924 - loss: 0.2671 - val_accuracy: 0.9050 - val_loss: 0.2573 - learning_rate: 2.4137e-04\n",
      "Epoch 222/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8759 - loss: 0.2997 - val_accuracy: 0.9106 - val_loss: 0.2550 - learning_rate: 2.4137e-04\n",
      "Epoch 223/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8868 - loss: 0.2918 - val_accuracy: 0.8827 - val_loss: 0.2621 - learning_rate: 2.4137e-04\n",
      "Epoch 224/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8800 - loss: 0.2814 - val_accuracy: 0.9050 - val_loss: 0.2544 - learning_rate: 2.4137e-04\n",
      "Epoch 225/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8782 - loss: 0.2800 - val_accuracy: 0.8994 - val_loss: 0.2663 - learning_rate: 2.4137e-04\n",
      "Epoch 226/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8667 - loss: 0.3003 - val_accuracy: 0.9162 - val_loss: 0.2500 - learning_rate: 2.4137e-04\n",
      "Epoch 227/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8759 - loss: 0.2800 - val_accuracy: 0.8939 - val_loss: 0.2556 - learning_rate: 2.4137e-04\n",
      "Epoch 228/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8687 - loss: 0.2962 - val_accuracy: 0.8994 - val_loss: 0.2692 - learning_rate: 2.4137e-04\n",
      "Epoch 229/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8826 - loss: 0.2797 - val_accuracy: 0.9106 - val_loss: 0.2528 - learning_rate: 2.4137e-04\n",
      "Epoch 230/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8871 - loss: 0.2853 - val_accuracy: 0.8994 - val_loss: 0.2583 - learning_rate: 2.4137e-04\n",
      "Epoch 231/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8797 - loss: 0.2903 - val_accuracy: 0.8994 - val_loss: 0.2532 - learning_rate: 2.4137e-04\n",
      "Epoch 232/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8846 - loss: 0.2959 - val_accuracy: 0.8939 - val_loss: 0.2532 - learning_rate: 2.4137e-04\n",
      "Epoch 233/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8937 - loss: 0.2577 - val_accuracy: 0.8994 - val_loss: 0.2554 - learning_rate: 2.4137e-04\n",
      "Epoch 234/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8674 - loss: 0.3002 - val_accuracy: 0.8771 - val_loss: 0.2670 - learning_rate: 2.4137e-04\n",
      "Epoch 235/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8804 - loss: 0.2892 - val_accuracy: 0.8994 - val_loss: 0.2609 - learning_rate: 2.4137e-04\n",
      "Epoch 236/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8781 - loss: 0.3068 - val_accuracy: 0.9050 - val_loss: 0.2491 - learning_rate: 2.4137e-04\n",
      "Epoch 237/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9010 - loss: 0.2615 - val_accuracy: 0.9106 - val_loss: 0.2430 - learning_rate: 2.4137e-04\n",
      "Epoch 238/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8865 - loss: 0.2816 - val_accuracy: 0.9106 - val_loss: 0.2513 - learning_rate: 2.4137e-04\n",
      "Epoch 239/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8886 - loss: 0.2728 - val_accuracy: 0.8883 - val_loss: 0.2452 - learning_rate: 2.4137e-04\n",
      "Epoch 240/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8892 - loss: 0.2772 - val_accuracy: 0.9050 - val_loss: 0.2568 - learning_rate: 2.4137e-04\n",
      "Epoch 241/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8736 - loss: 0.3065 - val_accuracy: 0.8994 - val_loss: 0.2574 - learning_rate: 2.4137e-04\n",
      "Epoch 242/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8818 - loss: 0.2849 - val_accuracy: 0.8994 - val_loss: 0.2504 - learning_rate: 2.4137e-04\n",
      "Epoch 243/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8694 - loss: 0.2948 - val_accuracy: 0.9162 - val_loss: 0.2476 - learning_rate: 2.4137e-04\n",
      "Epoch 244/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8861 - loss: 0.2803 - val_accuracy: 0.8939 - val_loss: 0.2525 - learning_rate: 2.4137e-04\n",
      "Epoch 245/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8971 - loss: 0.2769 - val_accuracy: 0.9050 - val_loss: 0.2552 - learning_rate: 2.4137e-04\n",
      "Epoch 246/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8918 - loss: 0.2711 - val_accuracy: 0.9162 - val_loss: 0.2471 - learning_rate: 2.4137e-04\n",
      "Epoch 247/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8792 - loss: 0.2876 - val_accuracy: 0.9162 - val_loss: 0.2457 - learning_rate: 2.4137e-04\n",
      "Epoch 248/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8811 - loss: 0.2718 - val_accuracy: 0.9050 - val_loss: 0.2564 - learning_rate: 2.4137e-04\n",
      "Epoch 249/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9016 - loss: 0.2643 - val_accuracy: 0.9106 - val_loss: 0.2436 - learning_rate: 2.4137e-04\n",
      "Epoch 250/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8846 - loss: 0.2932 - val_accuracy: 0.9162 - val_loss: 0.2465 - learning_rate: 2.4137e-04\n",
      "Epoch 251/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8852 - loss: 0.2828 - val_accuracy: 0.9050 - val_loss: 0.2502 - learning_rate: 2.4137e-04\n",
      "Epoch 252/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8828 - loss: 0.2962 - val_accuracy: 0.8994 - val_loss: 0.2479 - learning_rate: 2.4137e-04\n",
      "Epoch 253/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8870 - loss: 0.2632 - val_accuracy: 0.8994 - val_loss: 0.2515 - learning_rate: 2.4137e-04\n",
      "Epoch 254/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8882 - loss: 0.2731 - val_accuracy: 0.9106 - val_loss: 0.2510 - learning_rate: 2.4137e-04\n",
      "Epoch 255/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8833 - loss: 0.2738 - val_accuracy: 0.9106 - val_loss: 0.2470 - learning_rate: 2.4137e-04\n",
      "Epoch 256/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8772 - loss: 0.2902 - val_accuracy: 0.9162 - val_loss: 0.2463 - learning_rate: 2.4137e-04\n",
      "Epoch 257/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8915 - loss: 0.2659 - val_accuracy: 0.8771 - val_loss: 0.2519 - learning_rate: 2.4137e-04\n",
      "Epoch 258/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8835 - loss: 0.2601 - val_accuracy: 0.9106 - val_loss: 0.2426 - learning_rate: 2.4137e-04\n",
      "Epoch 259/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9026 - loss: 0.2592 - val_accuracy: 0.9106 - val_loss: 0.2476 - learning_rate: 2.4137e-04\n",
      "Epoch 260/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8744 - loss: 0.2949 - val_accuracy: 0.9162 - val_loss: 0.2459 - learning_rate: 2.4137e-04\n",
      "Epoch 261/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8750 - loss: 0.2895 - val_accuracy: 0.9106 - val_loss: 0.2424 - learning_rate: 2.4137e-04\n",
      "Epoch 262/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9066 - loss: 0.2414 - val_accuracy: 0.9050 - val_loss: 0.2457 - learning_rate: 2.4137e-04\n",
      "Epoch 263/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8820 - loss: 0.2871 - val_accuracy: 0.8939 - val_loss: 0.2482 - learning_rate: 2.4137e-04\n",
      "Epoch 264/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8743 - loss: 0.2806 - val_accuracy: 0.8994 - val_loss: 0.2492 - learning_rate: 2.4137e-04\n",
      "Epoch 265/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8854 - loss: 0.2788 - val_accuracy: 0.8939 - val_loss: 0.2458 - learning_rate: 2.4137e-04\n",
      "Epoch 266/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8966 - loss: 0.2576 - val_accuracy: 0.9106 - val_loss: 0.2418 - learning_rate: 2.4137e-04\n",
      "Epoch 267/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8808 - loss: 0.2821 - val_accuracy: 0.9050 - val_loss: 0.2438 - learning_rate: 2.4137e-04\n",
      "Epoch 268/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8918 - loss: 0.2769 - val_accuracy: 0.9162 - val_loss: 0.2402 - learning_rate: 2.4137e-04\n",
      "Epoch 269/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8815 - loss: 0.2835 - val_accuracy: 0.9050 - val_loss: 0.2472 - learning_rate: 2.4137e-04\n",
      "Epoch 270/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8823 - loss: 0.2775 - val_accuracy: 0.8827 - val_loss: 0.2610 - learning_rate: 2.4137e-04\n",
      "Epoch 271/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8918 - loss: 0.2667 - val_accuracy: 0.9218 - val_loss: 0.2422 - learning_rate: 2.4137e-04\n",
      "Epoch 272/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8898 - loss: 0.2842 - val_accuracy: 0.8715 - val_loss: 0.2631 - learning_rate: 2.4137e-04\n",
      "Epoch 273/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8740 - loss: 0.2876 - val_accuracy: 0.9162 - val_loss: 0.2480 - learning_rate: 2.4137e-04\n",
      "Epoch 274/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8998 - loss: 0.2629 - val_accuracy: 0.9050 - val_loss: 0.2483 - learning_rate: 2.4137e-04\n",
      "Epoch 275/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8805 - loss: 0.2737 - val_accuracy: 0.9106 - val_loss: 0.2448 - learning_rate: 2.4137e-04\n",
      "Epoch 276/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8901 - loss: 0.2715 - val_accuracy: 0.9050 - val_loss: 0.2388 - learning_rate: 2.4137e-04\n",
      "Epoch 277/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8849 - loss: 0.2877 - val_accuracy: 0.9162 - val_loss: 0.2331 - learning_rate: 2.4137e-04\n",
      "Epoch 278/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8826 - loss: 0.2720 - val_accuracy: 0.9218 - val_loss: 0.2363 - learning_rate: 2.4137e-04\n",
      "Epoch 279/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8950 - loss: 0.2577 - val_accuracy: 0.9218 - val_loss: 0.2363 - learning_rate: 2.4137e-04\n",
      "Epoch 280/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8871 - loss: 0.2755 - val_accuracy: 0.9050 - val_loss: 0.2448 - learning_rate: 2.4137e-04\n",
      "Epoch 281/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9081 - loss: 0.2532 - val_accuracy: 0.9218 - val_loss: 0.2433 - learning_rate: 2.4137e-04\n",
      "Epoch 282/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8557 - loss: 0.2984 - val_accuracy: 0.8994 - val_loss: 0.2527 - learning_rate: 2.4137e-04\n",
      "Epoch 283/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8688 - loss: 0.2975 - val_accuracy: 0.9106 - val_loss: 0.2524 - learning_rate: 2.4137e-04\n",
      "Epoch 284/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8775 - loss: 0.2815 - val_accuracy: 0.9106 - val_loss: 0.2406 - learning_rate: 2.4137e-04\n",
      "Epoch 285/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8778 - loss: 0.2834 - val_accuracy: 0.9274 - val_loss: 0.2294 - learning_rate: 2.4137e-04\n",
      "Epoch 286/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8827 - loss: 0.2872 - val_accuracy: 0.8994 - val_loss: 0.2422 - learning_rate: 2.4137e-04\n",
      "Epoch 287/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8649 - loss: 0.2965 - val_accuracy: 0.9218 - val_loss: 0.2399 - learning_rate: 2.4137e-04\n",
      "Epoch 288/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8978 - loss: 0.2662 - val_accuracy: 0.9050 - val_loss: 0.2451 - learning_rate: 2.4137e-04\n",
      "Epoch 289/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8923 - loss: 0.2682 - val_accuracy: 0.9106 - val_loss: 0.2404 - learning_rate: 2.4137e-04\n",
      "Epoch 290/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8742 - loss: 0.2801 - val_accuracy: 0.9218 - val_loss: 0.2359 - learning_rate: 2.4137e-04\n",
      "Epoch 291/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8928 - loss: 0.2684 - val_accuracy: 0.9162 - val_loss: 0.2321 - learning_rate: 2.4137e-04\n",
      "Epoch 292/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8826 - loss: 0.2913 - val_accuracy: 0.9106 - val_loss: 0.2345 - learning_rate: 2.4137e-04\n",
      "Epoch 293/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8904 - loss: 0.2693 - val_accuracy: 0.9106 - val_loss: 0.2393 - learning_rate: 2.4137e-04\n",
      "Epoch 294/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8877 - loss: 0.2582 - val_accuracy: 0.9218 - val_loss: 0.2362 - learning_rate: 2.4137e-04\n",
      "Epoch 295/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8801 - loss: 0.2817 - val_accuracy: 0.8939 - val_loss: 0.2413 - learning_rate: 2.4137e-04\n",
      "Epoch 296/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8762 - loss: 0.2642 - val_accuracy: 0.9106 - val_loss: 0.2362 - learning_rate: 2.4137e-04\n",
      "Epoch 297/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8944 - loss: 0.2544 - val_accuracy: 0.9106 - val_loss: 0.2342 - learning_rate: 2.4137e-04\n",
      "Epoch 298/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8899 - loss: 0.2808 - val_accuracy: 0.9106 - val_loss: 0.2392 - learning_rate: 2.4137e-04\n",
      "Epoch 299/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8978 - loss: 0.2651 - val_accuracy: 0.8994 - val_loss: 0.2399 - learning_rate: 2.4137e-04\n",
      "Epoch 300/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8866 - loss: 0.2679 - val_accuracy: 0.9274 - val_loss: 0.2310 - learning_rate: 2.4137e-04\n",
      "Epoch 301/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8876 - loss: 0.2677 - val_accuracy: 0.9162 - val_loss: 0.2319 - learning_rate: 2.4137e-04\n",
      "Epoch 302/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8877 - loss: 0.2652 - val_accuracy: 0.8994 - val_loss: 0.2451 - learning_rate: 2.4137e-04\n",
      "Epoch 303/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8918 - loss: 0.2712 - val_accuracy: 0.8939 - val_loss: 0.2364 - learning_rate: 2.4137e-04\n",
      "Epoch 304/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8838 - loss: 0.2808 - val_accuracy: 0.9050 - val_loss: 0.2350 - learning_rate: 2.4137e-04\n",
      "Epoch 305/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8927 - loss: 0.2662 - val_accuracy: 0.9162 - val_loss: 0.2325 - learning_rate: 2.4137e-04\n",
      "Epoch 306/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8813 - loss: 0.2656 - val_accuracy: 0.9218 - val_loss: 0.2337 - learning_rate: 2.4137e-04\n",
      "Epoch 307/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8904 - loss: 0.2629 - val_accuracy: 0.9106 - val_loss: 0.2337 - learning_rate: 2.4137e-04\n",
      "Epoch 308/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8850 - loss: 0.2801 - val_accuracy: 0.8883 - val_loss: 0.2403 - learning_rate: 2.4137e-04\n",
      "Epoch 309/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8877 - loss: 0.2559 - val_accuracy: 0.9218 - val_loss: 0.2291 - learning_rate: 2.4137e-04\n",
      "Epoch 310/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8860 - loss: 0.2650 - val_accuracy: 0.8994 - val_loss: 0.2401 - learning_rate: 2.4137e-04\n",
      "Epoch 311/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8849 - loss: 0.2735 - val_accuracy: 0.9218 - val_loss: 0.2332 - learning_rate: 2.4137e-04\n",
      "Epoch 312/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8945 - loss: 0.2634 - val_accuracy: 0.9218 - val_loss: 0.2296 - learning_rate: 2.4137e-04\n",
      "Epoch 313/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9031 - loss: 0.2551 - val_accuracy: 0.9218 - val_loss: 0.2286 - learning_rate: 2.4137e-04\n",
      "Epoch 314/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8911 - loss: 0.2733 - val_accuracy: 0.9162 - val_loss: 0.2338 - learning_rate: 2.4137e-04\n",
      "Epoch 315/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8719 - loss: 0.3002 - val_accuracy: 0.9162 - val_loss: 0.2325 - learning_rate: 2.4137e-04\n",
      "Epoch 316/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9035 - loss: 0.2274 - val_accuracy: 0.9106 - val_loss: 0.2352 - learning_rate: 2.4137e-04\n",
      "Epoch 317/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8905 - loss: 0.2772 - val_accuracy: 0.9050 - val_loss: 0.2392 - learning_rate: 2.4137e-04\n",
      "Epoch 318/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8952 - loss: 0.2763 - val_accuracy: 0.9218 - val_loss: 0.2237 - learning_rate: 2.4137e-04\n",
      "Epoch 319/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8949 - loss: 0.2721 - val_accuracy: 0.9162 - val_loss: 0.2346 - learning_rate: 2.4137e-04\n",
      "Epoch 320/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8966 - loss: 0.2576 - val_accuracy: 0.8994 - val_loss: 0.2375 - learning_rate: 2.4137e-04\n",
      "Epoch 321/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8711 - loss: 0.2709 - val_accuracy: 0.9162 - val_loss: 0.2286 - learning_rate: 2.4137e-04\n",
      "Epoch 322/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8862 - loss: 0.2695 - val_accuracy: 0.9050 - val_loss: 0.2287 - learning_rate: 2.4137e-04\n",
      "Epoch 323/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8919 - loss: 0.2673 - val_accuracy: 0.8994 - val_loss: 0.2366 - learning_rate: 2.4137e-04\n",
      "Epoch 324/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9023 - loss: 0.2451 - val_accuracy: 0.9162 - val_loss: 0.2278 - learning_rate: 2.4137e-04\n",
      "Epoch 325/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8838 - loss: 0.2740 - val_accuracy: 0.9218 - val_loss: 0.2317 - learning_rate: 2.4137e-04\n",
      "Epoch 326/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8920 - loss: 0.2724 - val_accuracy: 0.9162 - val_loss: 0.2321 - learning_rate: 2.4137e-04\n",
      "Epoch 327/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8854 - loss: 0.2637 - val_accuracy: 0.9106 - val_loss: 0.2355 - learning_rate: 2.4137e-04\n",
      "Epoch 328/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8855 - loss: 0.2731 - val_accuracy: 0.8994 - val_loss: 0.2409 - learning_rate: 2.4137e-04\n",
      "Epoch 329/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8739 - loss: 0.2750 - val_accuracy: 0.9050 - val_loss: 0.2321 - learning_rate: 2.4137e-04\n",
      "Epoch 330/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8939 - loss: 0.2705 - val_accuracy: 0.9162 - val_loss: 0.2299 - learning_rate: 2.4137e-04\n",
      "Epoch 331/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8927 - loss: 0.2519 - val_accuracy: 0.9274 - val_loss: 0.2300 - learning_rate: 2.4137e-04\n",
      "Epoch 332/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8914 - loss: 0.2611 - val_accuracy: 0.9050 - val_loss: 0.2331 - learning_rate: 2.4137e-04\n",
      "Epoch 333/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8831 - loss: 0.2634 - val_accuracy: 0.9106 - val_loss: 0.2311 - learning_rate: 2.4137e-04\n",
      "Epoch 334/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8933 - loss: 0.2618 - val_accuracy: 0.9274 - val_loss: 0.2236 - learning_rate: 2.4137e-04\n",
      "Epoch 335/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8891 - loss: 0.2561 - val_accuracy: 0.9162 - val_loss: 0.2313 - learning_rate: 2.4137e-04\n",
      "Epoch 336/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8877 - loss: 0.2616 - val_accuracy: 0.9106 - val_loss: 0.2226 - learning_rate: 2.4137e-04\n",
      "Epoch 337/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9062 - loss: 0.2554 - val_accuracy: 0.9162 - val_loss: 0.2295 - learning_rate: 2.4137e-04\n",
      "Epoch 338/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9030 - loss: 0.2415 - val_accuracy: 0.9106 - val_loss: 0.2293 - learning_rate: 2.4137e-04\n",
      "Epoch 339/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9020 - loss: 0.2482 - val_accuracy: 0.9218 - val_loss: 0.2281 - learning_rate: 2.4137e-04\n",
      "Epoch 340/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9128 - loss: 0.2308 - val_accuracy: 0.9106 - val_loss: 0.2276 - learning_rate: 2.4137e-04\n",
      "Epoch 341/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9001 - loss: 0.2608 - val_accuracy: 0.9162 - val_loss: 0.2307 - learning_rate: 2.4137e-04\n",
      "Epoch 342/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9008 - loss: 0.2404 - val_accuracy: 0.9218 - val_loss: 0.2322 - learning_rate: 2.4137e-04\n",
      "Epoch 343/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9034 - loss: 0.2412 - val_accuracy: 0.8994 - val_loss: 0.2359 - learning_rate: 2.4137e-04\n",
      "Epoch 344/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8883 - loss: 0.2699 - val_accuracy: 0.9162 - val_loss: 0.2287 - learning_rate: 2.4137e-04\n",
      "Epoch 345/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8977 - loss: 0.2559 - val_accuracy: 0.9218 - val_loss: 0.2219 - learning_rate: 2.4137e-04\n",
      "Epoch 346/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8872 - loss: 0.2732 - val_accuracy: 0.9162 - val_loss: 0.2238 - learning_rate: 2.4137e-04\n",
      "Epoch 347/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8905 - loss: 0.2644 - val_accuracy: 0.9106 - val_loss: 0.2304 - learning_rate: 2.4137e-04\n",
      "Epoch 348/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9226 - loss: 0.2247 - val_accuracy: 0.9218 - val_loss: 0.2226 - learning_rate: 2.4137e-04\n",
      "Epoch 349/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9049 - loss: 0.2390 - val_accuracy: 0.9218 - val_loss: 0.2290 - learning_rate: 2.4137e-04\n",
      "Epoch 350/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8986 - loss: 0.2600 - val_accuracy: 0.9050 - val_loss: 0.2372 - learning_rate: 2.4137e-04\n",
      "Epoch 351/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9012 - loss: 0.2471 - val_accuracy: 0.9162 - val_loss: 0.2253 - learning_rate: 2.4137e-04\n",
      "Epoch 352/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8809 - loss: 0.2779 - val_accuracy: 0.9274 - val_loss: 0.2224 - learning_rate: 2.4137e-04\n",
      "Epoch 353/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8780 - loss: 0.2714 - val_accuracy: 0.8994 - val_loss: 0.2355 - learning_rate: 2.4137e-04\n",
      "Epoch 354/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8961 - loss: 0.2467 - val_accuracy: 0.9162 - val_loss: 0.2262 - learning_rate: 2.4137e-04\n",
      "Epoch 355/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8817 - loss: 0.2770 - val_accuracy: 0.9162 - val_loss: 0.2228 - learning_rate: 2.4137e-04\n",
      "Epoch 356/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8972 - loss: 0.2596 - val_accuracy: 0.9218 - val_loss: 0.2251 - learning_rate: 2.4137e-04\n",
      "Epoch 357/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8906 - loss: 0.2562 - val_accuracy: 0.9106 - val_loss: 0.2312 - learning_rate: 2.4137e-04\n",
      "Epoch 358/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8905 - loss: 0.2770 - val_accuracy: 0.9162 - val_loss: 0.2279 - learning_rate: 2.4137e-04\n",
      "Epoch 359/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8901 - loss: 0.2624 - val_accuracy: 0.9162 - val_loss: 0.2224 - learning_rate: 2.4137e-04\n",
      "Epoch 360/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8967 - loss: 0.2556 - val_accuracy: 0.9050 - val_loss: 0.2324 - learning_rate: 2.4137e-04\n",
      "Epoch 361/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8831 - loss: 0.2752 - val_accuracy: 0.9050 - val_loss: 0.2360 - learning_rate: 2.4137e-04\n",
      "Epoch 362/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8770 - loss: 0.2912 - val_accuracy: 0.9162 - val_loss: 0.2307 - learning_rate: 2.4137e-04\n",
      "Epoch 363/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9037 - loss: 0.2515 - val_accuracy: 0.9218 - val_loss: 0.2255 - learning_rate: 2.4137e-04\n",
      "Epoch 364/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9016 - loss: 0.2484 - val_accuracy: 0.9050 - val_loss: 0.2252 - learning_rate: 2.4137e-04\n",
      "Epoch 365/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8805 - loss: 0.2651 - val_accuracy: 0.9106 - val_loss: 0.2270 - learning_rate: 2.4137e-04\n",
      "Epoch 366/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8883 - loss: 0.2587 - val_accuracy: 0.9050 - val_loss: 0.2251 - learning_rate: 2.4137e-04\n",
      "Epoch 367/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9021 - loss: 0.2473 - val_accuracy: 0.9162 - val_loss: 0.2277 - learning_rate: 2.4137e-04\n",
      "Epoch 368/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8901 - loss: 0.2504 - val_accuracy: 0.9106 - val_loss: 0.2239 - learning_rate: 2.4137e-04\n",
      "Epoch 369/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8951 - loss: 0.2588 - val_accuracy: 0.9162 - val_loss: 0.2194 - learning_rate: 2.4137e-04\n",
      "Epoch 370/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9076 - loss: 0.2376 - val_accuracy: 0.9106 - val_loss: 0.2285 - learning_rate: 2.4137e-04\n",
      "Epoch 371/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8993 - loss: 0.2578 - val_accuracy: 0.9162 - val_loss: 0.2235 - learning_rate: 2.4137e-04\n",
      "Epoch 372/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8822 - loss: 0.2663 - val_accuracy: 0.9274 - val_loss: 0.2181 - learning_rate: 2.4137e-04\n",
      "Epoch 373/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8986 - loss: 0.2424 - val_accuracy: 0.9106 - val_loss: 0.2212 - learning_rate: 2.4137e-04\n",
      "Epoch 374/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8879 - loss: 0.2578 - val_accuracy: 0.9050 - val_loss: 0.2222 - learning_rate: 2.4137e-04\n",
      "Epoch 375/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9034 - loss: 0.2373 - val_accuracy: 0.9162 - val_loss: 0.2229 - learning_rate: 2.4137e-04\n",
      "Epoch 376/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9058 - loss: 0.2404 - val_accuracy: 0.9218 - val_loss: 0.2202 - learning_rate: 2.4137e-04\n",
      "Epoch 377/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8847 - loss: 0.2729 - val_accuracy: 0.9274 - val_loss: 0.2208 - learning_rate: 2.4137e-04\n",
      "Epoch 378/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8995 - loss: 0.2455 - val_accuracy: 0.9385 - val_loss: 0.2221 - learning_rate: 2.4137e-04\n",
      "Epoch 379/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8897 - loss: 0.2745 - val_accuracy: 0.9106 - val_loss: 0.2235 - learning_rate: 2.4137e-04\n",
      "Epoch 380/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9017 - loss: 0.2528 - val_accuracy: 0.9050 - val_loss: 0.2233 - learning_rate: 2.4137e-04\n",
      "Epoch 381/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8933 - loss: 0.2565 - val_accuracy: 0.9274 - val_loss: 0.2181 - learning_rate: 2.4137e-04\n",
      "Epoch 382/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8902 - loss: 0.2511 - val_accuracy: 0.9218 - val_loss: 0.2247 - learning_rate: 2.4137e-04\n",
      "Epoch 383/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9063 - loss: 0.2494 - val_accuracy: 0.9274 - val_loss: 0.2191 - learning_rate: 2.4137e-04\n",
      "Epoch 384/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8898 - loss: 0.2562 - val_accuracy: 0.9218 - val_loss: 0.2201 - learning_rate: 2.4137e-04\n",
      "Epoch 385/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8915 - loss: 0.2557 - val_accuracy: 0.9162 - val_loss: 0.2231 - learning_rate: 2.4137e-04\n",
      "Epoch 386/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8868 - loss: 0.2722 - val_accuracy: 0.9162 - val_loss: 0.2206 - learning_rate: 2.4137e-04\n",
      "Epoch 387/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8977 - loss: 0.2464 - val_accuracy: 0.9274 - val_loss: 0.2189 - learning_rate: 2.4137e-04\n",
      "Epoch 388/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8977 - loss: 0.2495 - val_accuracy: 0.9106 - val_loss: 0.2291 - learning_rate: 2.4137e-04\n",
      "Epoch 389/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8785 - loss: 0.2778 - val_accuracy: 0.9162 - val_loss: 0.2266 - learning_rate: 2.4137e-04\n",
      "Epoch 390/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9014 - loss: 0.2581 - val_accuracy: 0.9218 - val_loss: 0.2202 - learning_rate: 2.4137e-04\n",
      "Epoch 391/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8841 - loss: 0.2583 - val_accuracy: 0.9162 - val_loss: 0.2224 - learning_rate: 2.4137e-04\n",
      "Epoch 392/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8850 - loss: 0.2529 - val_accuracy: 0.9106 - val_loss: 0.2246 - learning_rate: 2.4137e-04\n",
      "Epoch 393/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8980 - loss: 0.2426 - val_accuracy: 0.9106 - val_loss: 0.2244 - learning_rate: 2.4137e-04\n",
      "Epoch 394/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8995 - loss: 0.2543 - val_accuracy: 0.9274 - val_loss: 0.2144 - learning_rate: 2.4137e-04\n",
      "Epoch 395/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9007 - loss: 0.2501 - val_accuracy: 0.9218 - val_loss: 0.2196 - learning_rate: 2.4137e-04\n",
      "Epoch 396/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8947 - loss: 0.2459 - val_accuracy: 0.9330 - val_loss: 0.2188 - learning_rate: 2.4137e-04\n",
      "Epoch 397/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9017 - loss: 0.2444 - val_accuracy: 0.9050 - val_loss: 0.2210 - learning_rate: 2.4137e-04\n",
      "Epoch 398/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8920 - loss: 0.2446 - val_accuracy: 0.9218 - val_loss: 0.2174 - learning_rate: 2.4137e-04\n",
      "Epoch 399/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8902 - loss: 0.2505 - val_accuracy: 0.9218 - val_loss: 0.2187 - learning_rate: 2.4137e-04\n",
      "Epoch 400/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8980 - loss: 0.2624 - val_accuracy: 0.9274 - val_loss: 0.2188 - learning_rate: 2.4137e-04\n",
      "Epoch 401/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8977 - loss: 0.2395 - val_accuracy: 0.9274 - val_loss: 0.2104 - learning_rate: 2.4137e-04\n",
      "Epoch 402/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9052 - loss: 0.2435 - val_accuracy: 0.9274 - val_loss: 0.2132 - learning_rate: 2.4137e-04\n",
      "Epoch 403/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8961 - loss: 0.2458 - val_accuracy: 0.9162 - val_loss: 0.2198 - learning_rate: 2.4137e-04\n",
      "Epoch 404/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8992 - loss: 0.2523 - val_accuracy: 0.9218 - val_loss: 0.2169 - learning_rate: 2.4137e-04\n",
      "Epoch 405/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9015 - loss: 0.2449 - val_accuracy: 0.9274 - val_loss: 0.2177 - learning_rate: 2.4137e-04\n",
      "Epoch 406/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9038 - loss: 0.2558 - val_accuracy: 0.9162 - val_loss: 0.2236 - learning_rate: 2.4137e-04\n",
      "Epoch 407/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9038 - loss: 0.2261 - val_accuracy: 0.9274 - val_loss: 0.2132 - learning_rate: 2.4137e-04\n",
      "Epoch 408/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8895 - loss: 0.2540 - val_accuracy: 0.9385 - val_loss: 0.2140 - learning_rate: 2.4137e-04\n",
      "Epoch 409/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8916 - loss: 0.2506 - val_accuracy: 0.8939 - val_loss: 0.2296 - learning_rate: 2.4137e-04\n",
      "Epoch 410/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8931 - loss: 0.2451 - val_accuracy: 0.9162 - val_loss: 0.2192 - learning_rate: 2.4137e-04\n",
      "Epoch 411/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9080 - loss: 0.2388 - val_accuracy: 0.9162 - val_loss: 0.2180 - learning_rate: 2.4137e-04\n",
      "Epoch 412/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8870 - loss: 0.2657 - val_accuracy: 0.9274 - val_loss: 0.2182 - learning_rate: 2.4137e-04\n",
      "Epoch 413/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8855 - loss: 0.2793 - val_accuracy: 0.9162 - val_loss: 0.2177 - learning_rate: 2.4137e-04\n",
      "Epoch 414/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8857 - loss: 0.2578 - val_accuracy: 0.9218 - val_loss: 0.2158 - learning_rate: 2.4137e-04\n",
      "Epoch 415/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9103 - loss: 0.2373 - val_accuracy: 0.9274 - val_loss: 0.2187 - learning_rate: 2.4137e-04\n",
      "Epoch 416/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8978 - loss: 0.2464 - val_accuracy: 0.9106 - val_loss: 0.2251 - learning_rate: 2.4137e-04\n",
      "Epoch 417/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8975 - loss: 0.2309 - val_accuracy: 0.9274 - val_loss: 0.2140 - learning_rate: 2.4137e-04\n",
      "Epoch 418/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9002 - loss: 0.2630 - val_accuracy: 0.9218 - val_loss: 0.2168 - learning_rate: 2.4137e-04\n",
      "Epoch 419/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9056 - loss: 0.2381 - val_accuracy: 0.9106 - val_loss: 0.2207 - learning_rate: 2.4137e-04\n",
      "Epoch 420/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8987 - loss: 0.2390 - val_accuracy: 0.9162 - val_loss: 0.2211 - learning_rate: 2.4137e-04\n",
      "Epoch 421/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9044 - loss: 0.2448 - val_accuracy: 0.9274 - val_loss: 0.2115 - learning_rate: 2.4137e-04\n",
      "Epoch 422/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8950 - loss: 0.2578 - val_accuracy: 0.9218 - val_loss: 0.2242 - learning_rate: 2.4137e-04\n",
      "Epoch 423/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9076 - loss: 0.2276 - val_accuracy: 0.9218 - val_loss: 0.2167 - learning_rate: 2.4137e-04\n",
      "Epoch 424/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8914 - loss: 0.2669 - val_accuracy: 0.9330 - val_loss: 0.2122 - learning_rate: 2.4137e-04\n",
      "Epoch 425/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9055 - loss: 0.2304 - val_accuracy: 0.9385 - val_loss: 0.2106 - learning_rate: 2.4137e-04\n",
      "Epoch 426/550\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8870 - loss: 0.2777 - val_accuracy: 0.8994 - val_loss: 0.2227 - learning_rate: 2.4137e-04\n"
     ]
    }
   ],
   "source": [
    "# Get the top 2 hyperparameters.\n",
    "best_hps = tuner_11.get_best_hyperparameters(5)\n",
    "# Build the model with the best hp.\n",
    "model_X = build_model_11(best_hps[0])\n",
    "model_Z = tuner_11.get_best_models()[0]\n",
    "# Fit with the entire dataset.\n",
    "x_all = np.concatenate((X_train, X_valid))\n",
    "y_all = np.concatenate((y_train, y_valid))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=25, min_lr=1e-6)\n",
    "\n",
    "history_X = model_X.fit(x=x_all, \n",
    "            y=y_all, \n",
    "            epochs=550, \n",
    "            verbose=1, \n",
    "            batch_size=128,\n",
    "            validation_data=(X_valid, y_valid),\n",
    "            callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7709497213363647,\n",
       " 0.7821229100227356,\n",
       " 0.7821229100227356,\n",
       " 0.7821229100227356,\n",
       " 0.8044692873954773,\n",
       " 0.8100558519363403,\n",
       " 0.8212290406227112,\n",
       " 0.8156424760818481,\n",
       " 0.8156424760818481,\n",
       " 0.8156424760818481,\n",
       " 0.8100558519363403,\n",
       " 0.826815664768219,\n",
       " 0.832402229309082,\n",
       " 0.8212290406227112,\n",
       " 0.8212290406227112,\n",
       " 0.826815664768219,\n",
       " 0.832402229309082,\n",
       " 0.8212290406227112,\n",
       " 0.826815664768219,\n",
       " 0.826815664768219,\n",
       " 0.832402229309082,\n",
       " 0.826815664768219,\n",
       " 0.832402229309082,\n",
       " 0.832402229309082,\n",
       " 0.832402229309082,\n",
       " 0.8491619825363159,\n",
       " 0.832402229309082,\n",
       " 0.8379888534545898,\n",
       " 0.8379888534545898,\n",
       " 0.8379888534545898,\n",
       " 0.8379888534545898,\n",
       " 0.8435754179954529,\n",
       " 0.8491619825363159,\n",
       " 0.8435754179954529,\n",
       " 0.8491619825363159,\n",
       " 0.8435754179954529,\n",
       " 0.8491619825363159,\n",
       " 0.832402229309082,\n",
       " 0.8491619825363159,\n",
       " 0.8435754179954529,\n",
       " 0.8435754179954529,\n",
       " 0.8379888534545898,\n",
       " 0.8491619825363159,\n",
       " 0.8491619825363159,\n",
       " 0.8435754179954529,\n",
       " 0.8491619825363159,\n",
       " 0.8379888534545898,\n",
       " 0.8491619825363159,\n",
       " 0.8435754179954529,\n",
       " 0.8547486066818237,\n",
       " 0.8491619825363159,\n",
       " 0.8491619825363159,\n",
       " 0.8547486066818237,\n",
       " 0.8547486066818237,\n",
       " 0.8491619825363159,\n",
       " 0.8491619825363159,\n",
       " 0.8491619825363159,\n",
       " 0.8435754179954529,\n",
       " 0.8491619825363159,\n",
       " 0.8491619825363159,\n",
       " 0.8491619825363159,\n",
       " 0.8491619825363159,\n",
       " 0.8491619825363159,\n",
       " 0.8547486066818237,\n",
       " 0.8435754179954529,\n",
       " 0.8491619825363159,\n",
       " 0.8491619825363159,\n",
       " 0.8435754179954529,\n",
       " 0.8491619825363159,\n",
       " 0.8435754179954529,\n",
       " 0.8435754179954529,\n",
       " 0.8435754179954529,\n",
       " 0.8435754179954529,\n",
       " 0.8491619825363159,\n",
       " 0.8435754179954529,\n",
       " 0.8435754179954529,\n",
       " 0.8435754179954529,\n",
       " 0.8491619825363159,\n",
       " 0.8491619825363159,\n",
       " 0.8435754179954529,\n",
       " 0.8435754179954529,\n",
       " 0.8491619825363159,\n",
       " 0.8491619825363159,\n",
       " 0.8435754179954529,\n",
       " 0.8491619825363159,\n",
       " 0.8435754179954529,\n",
       " 0.8435754179954529,\n",
       " 0.8435754179954529,\n",
       " 0.8435754179954529,\n",
       " 0.8435754179954529,\n",
       " 0.8435754179954529,\n",
       " 0.8491619825363159,\n",
       " 0.8435754179954529,\n",
       " 0.8491619825363159,\n",
       " 0.8435754179954529,\n",
       " 0.8435754179954529,\n",
       " 0.8491619825363159,\n",
       " 0.8435754179954529,\n",
       " 0.8435754179954529,\n",
       " 0.8435754179954529,\n",
       " 0.8491619825363159,\n",
       " 0.8435754179954529,\n",
       " 0.8603351712226868,\n",
       " 0.8491619825363159,\n",
       " 0.8435754179954529,\n",
       " 0.8491619825363159,\n",
       " 0.8435754179954529,\n",
       " 0.8435754179954529,\n",
       " 0.8715083599090576,\n",
       " 0.8491619825363159,\n",
       " 0.8435754179954529,\n",
       " 0.8659217953681946,\n",
       " 0.8491619825363159,\n",
       " 0.8659217953681946,\n",
       " 0.8659217953681946,\n",
       " 0.8547486066818237,\n",
       " 0.8491619825363159,\n",
       " 0.8491619825363159,\n",
       " 0.8603351712226868,\n",
       " 0.8435754179954529,\n",
       " 0.8659217953681946,\n",
       " 0.8659217953681946,\n",
       " 0.8603351712226868,\n",
       " 0.8491619825363159,\n",
       " 0.8659217953681946,\n",
       " 0.8379888534545898,\n",
       " 0.8491619825363159,\n",
       " 0.8826815485954285,\n",
       " 0.8435754179954529,\n",
       " 0.8547486066818237,\n",
       " 0.8826815485954285,\n",
       " 0.8715083599090576,\n",
       " 0.8491619825363159,\n",
       " 0.8770949840545654,\n",
       " 0.8882681727409363,\n",
       " 0.8659217953681946,\n",
       " 0.8715083599090576,\n",
       " 0.8491619825363159,\n",
       " 0.8826815485954285,\n",
       " 0.8547486066818237,\n",
       " 0.8770949840545654,\n",
       " 0.8435754179954529,\n",
       " 0.8826815485954285,\n",
       " 0.8547486066818237,\n",
       " 0.8491619825363159,\n",
       " 0.8826815485954285,\n",
       " 0.8659217953681946,\n",
       " 0.8491619825363159,\n",
       " 0.8715083599090576,\n",
       " 0.8826815485954285,\n",
       " 0.8770949840545654,\n",
       " 0.8715083599090576,\n",
       " 0.8491619825363159,\n",
       " 0.9050279259681702,\n",
       " 0.8491619825363159,\n",
       " 0.8826815485954285,\n",
       " 0.8770949840545654,\n",
       " 0.8715083599090576,\n",
       " 0.8603351712226868,\n",
       " 0.8547486066818237,\n",
       " 0.8826815485954285,\n",
       " 0.8715083599090576,\n",
       " 0.8491619825363159,\n",
       " 0.8938547372817993,\n",
       " 0.8547486066818237,\n",
       " 0.8994413614273071,\n",
       " 0.8659217953681946,\n",
       " 0.8882681727409363,\n",
       " 0.8938547372817993,\n",
       " 0.8882681727409363,\n",
       " 0.9050279259681702,\n",
       " 0.8826815485954285,\n",
       " 0.8882681727409363,\n",
       " 0.8715083599090576,\n",
       " 0.8938547372817993,\n",
       " 0.8826815485954285,\n",
       " 0.8826815485954285,\n",
       " 0.8938547372817993,\n",
       " 0.9050279259681702,\n",
       " 0.8938547372817993,\n",
       " 0.8882681727409363,\n",
       " 0.8938547372817993,\n",
       " 0.8826815485954285,\n",
       " 0.8938547372817993,\n",
       " 0.8770949840545654,\n",
       " 0.8938547372817993,\n",
       " 0.8826815485954285,\n",
       " 0.9050279259681702,\n",
       " 0.8994413614273071,\n",
       " 0.9050279259681702,\n",
       " 0.8938547372817993,\n",
       " 0.9050279259681702,\n",
       " 0.910614550113678,\n",
       " 0.8938547372817993,\n",
       " 0.8994413614273071,\n",
       " 0.8994413614273071,\n",
       " 0.8938547372817993,\n",
       " 0.910614550113678,\n",
       " 0.9050279259681702,\n",
       " 0.8715083599090576,\n",
       " 0.916201114654541,\n",
       " 0.8882681727409363,\n",
       " 0.9050279259681702,\n",
       " 0.8994413614273071,\n",
       " 0.8938547372817993,\n",
       " 0.8994413614273071,\n",
       " 0.8882681727409363,\n",
       " 0.910614550113678,\n",
       " 0.916201114654541,\n",
       " 0.8882681727409363,\n",
       " 0.8994413614273071,\n",
       " 0.8938547372817993,\n",
       " 0.8994413614273071,\n",
       " 0.916201114654541,\n",
       " 0.8994413614273071,\n",
       " 0.916201114654541,\n",
       " 0.9050279259681702,\n",
       " 0.916201114654541,\n",
       " 0.916201114654541,\n",
       " 0.9050279259681702,\n",
       " 0.9050279259681702,\n",
       " 0.910614550113678,\n",
       " 0.8826815485954285,\n",
       " 0.9050279259681702,\n",
       " 0.8994413614273071,\n",
       " 0.916201114654541,\n",
       " 0.8938547372817993,\n",
       " 0.8994413614273071,\n",
       " 0.910614550113678,\n",
       " 0.8994413614273071,\n",
       " 0.8994413614273071,\n",
       " 0.8938547372817993,\n",
       " 0.8994413614273071,\n",
       " 0.8770949840545654,\n",
       " 0.8994413614273071,\n",
       " 0.9050279259681702,\n",
       " 0.910614550113678,\n",
       " 0.910614550113678,\n",
       " 0.8882681727409363,\n",
       " 0.9050279259681702,\n",
       " 0.8994413614273071,\n",
       " 0.8994413614273071,\n",
       " 0.916201114654541,\n",
       " 0.8938547372817993,\n",
       " 0.9050279259681702,\n",
       " 0.916201114654541,\n",
       " 0.916201114654541,\n",
       " 0.9050279259681702,\n",
       " 0.910614550113678,\n",
       " 0.916201114654541,\n",
       " 0.9050279259681702,\n",
       " 0.8994413614273071,\n",
       " 0.8994413614273071,\n",
       " 0.910614550113678,\n",
       " 0.910614550113678,\n",
       " 0.916201114654541,\n",
       " 0.8770949840545654,\n",
       " 0.910614550113678,\n",
       " 0.910614550113678,\n",
       " 0.916201114654541,\n",
       " 0.910614550113678,\n",
       " 0.9050279259681702,\n",
       " 0.8938547372817993,\n",
       " 0.8994413614273071,\n",
       " 0.8938547372817993,\n",
       " 0.910614550113678,\n",
       " 0.9050279259681702,\n",
       " 0.916201114654541,\n",
       " 0.9050279259681702,\n",
       " 0.8826815485954285,\n",
       " 0.9217877388000488,\n",
       " 0.8715083599090576,\n",
       " 0.916201114654541,\n",
       " 0.9050279259681702,\n",
       " 0.910614550113678,\n",
       " 0.9050279259681702,\n",
       " 0.916201114654541,\n",
       " 0.9217877388000488,\n",
       " 0.9217877388000488,\n",
       " 0.9050279259681702,\n",
       " 0.9217877388000488,\n",
       " 0.8994413614273071,\n",
       " 0.910614550113678,\n",
       " 0.910614550113678,\n",
       " 0.9273743033409119,\n",
       " 0.8994413614273071,\n",
       " 0.9217877388000488,\n",
       " 0.9050279259681702,\n",
       " 0.910614550113678,\n",
       " 0.9217877388000488,\n",
       " 0.916201114654541,\n",
       " 0.910614550113678,\n",
       " 0.910614550113678,\n",
       " 0.9217877388000488,\n",
       " 0.8938547372817993,\n",
       " 0.910614550113678,\n",
       " 0.910614550113678,\n",
       " 0.910614550113678,\n",
       " 0.8994413614273071,\n",
       " 0.9273743033409119,\n",
       " 0.916201114654541,\n",
       " 0.8994413614273071,\n",
       " 0.8938547372817993,\n",
       " 0.9050279259681702,\n",
       " 0.916201114654541,\n",
       " 0.9217877388000488,\n",
       " 0.910614550113678,\n",
       " 0.8882681727409363,\n",
       " 0.9217877388000488,\n",
       " 0.8994413614273071,\n",
       " 0.9217877388000488,\n",
       " 0.9217877388000488,\n",
       " 0.9217877388000488,\n",
       " 0.916201114654541,\n",
       " 0.916201114654541,\n",
       " 0.910614550113678,\n",
       " 0.9050279259681702,\n",
       " 0.9217877388000488,\n",
       " 0.916201114654541,\n",
       " 0.8994413614273071,\n",
       " 0.916201114654541,\n",
       " 0.9050279259681702,\n",
       " 0.8994413614273071,\n",
       " 0.916201114654541,\n",
       " 0.9217877388000488,\n",
       " 0.916201114654541,\n",
       " 0.910614550113678,\n",
       " 0.8994413614273071,\n",
       " 0.9050279259681702,\n",
       " 0.916201114654541,\n",
       " 0.9273743033409119,\n",
       " 0.9050279259681702,\n",
       " 0.910614550113678,\n",
       " 0.9273743033409119,\n",
       " 0.916201114654541,\n",
       " 0.910614550113678,\n",
       " 0.916201114654541,\n",
       " 0.910614550113678,\n",
       " 0.9217877388000488,\n",
       " 0.910614550113678,\n",
       " 0.916201114654541,\n",
       " 0.9217877388000488,\n",
       " 0.8994413614273071,\n",
       " 0.916201114654541,\n",
       " 0.9217877388000488,\n",
       " 0.916201114654541,\n",
       " 0.910614550113678,\n",
       " 0.9217877388000488,\n",
       " 0.9217877388000488,\n",
       " 0.9050279259681702,\n",
       " 0.916201114654541,\n",
       " 0.9273743033409119,\n",
       " 0.8994413614273071,\n",
       " 0.916201114654541,\n",
       " 0.916201114654541,\n",
       " 0.9217877388000488,\n",
       " 0.910614550113678,\n",
       " 0.916201114654541,\n",
       " 0.916201114654541,\n",
       " 0.9050279259681702,\n",
       " 0.9050279259681702,\n",
       " 0.916201114654541,\n",
       " 0.9217877388000488,\n",
       " 0.9050279259681702,\n",
       " 0.910614550113678,\n",
       " 0.9050279259681702,\n",
       " 0.916201114654541,\n",
       " 0.910614550113678,\n",
       " 0.916201114654541,\n",
       " 0.910614550113678,\n",
       " 0.916201114654541,\n",
       " 0.9273743033409119,\n",
       " 0.910614550113678,\n",
       " 0.9050279259681702,\n",
       " 0.916201114654541,\n",
       " 0.9217877388000488,\n",
       " 0.9273743033409119,\n",
       " 0.9385474920272827,\n",
       " 0.910614550113678,\n",
       " 0.9050279259681702,\n",
       " 0.9273743033409119,\n",
       " 0.9217877388000488,\n",
       " 0.9273743033409119,\n",
       " 0.9217877388000488,\n",
       " 0.916201114654541,\n",
       " 0.916201114654541,\n",
       " 0.9273743033409119,\n",
       " 0.910614550113678,\n",
       " 0.916201114654541,\n",
       " 0.9217877388000488,\n",
       " 0.916201114654541,\n",
       " 0.910614550113678,\n",
       " 0.910614550113678,\n",
       " 0.9273743033409119,\n",
       " 0.9217877388000488,\n",
       " 0.9329608678817749,\n",
       " 0.9050279259681702,\n",
       " 0.9217877388000488,\n",
       " 0.9217877388000488,\n",
       " 0.9273743033409119,\n",
       " 0.9273743033409119,\n",
       " 0.9273743033409119,\n",
       " 0.916201114654541,\n",
       " 0.9217877388000488,\n",
       " 0.9273743033409119,\n",
       " 0.916201114654541,\n",
       " 0.9273743033409119,\n",
       " 0.9385474920272827,\n",
       " 0.8938547372817993,\n",
       " 0.916201114654541,\n",
       " 0.916201114654541,\n",
       " 0.9273743033409119,\n",
       " 0.916201114654541,\n",
       " 0.9217877388000488,\n",
       " 0.9273743033409119,\n",
       " 0.910614550113678,\n",
       " 0.9273743033409119,\n",
       " 0.9217877388000488,\n",
       " 0.910614550113678,\n",
       " 0.916201114654541,\n",
       " 0.9273743033409119,\n",
       " 0.9217877388000488,\n",
       " 0.9217877388000488,\n",
       " 0.9329608678817749,\n",
       " 0.9385474920272827,\n",
       " 0.8994413614273071]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_X.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_X.history['loss'])\n",
    "plt.plot(history_X.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_X.history['accuracy'])\n",
    "plt.plot(history_X.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Z = tuner_11.get_best_models()[0]\n",
    "model_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8583 - loss: 0.4171  \n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model_Z.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 1,\n",
       " 'units_0': 128,\n",
       " 'activation': 'relu',\n",
       " 'dropout': True,\n",
       " 'lr': 0.0002413710835604695}"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_h = tuner_11.get_best_hyperparameters()[0]\n",
    "best_h.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 128\n",
      "activation: relu\n",
      "dropout: True\n",
      "lr: 0.0002413710835604695\n",
      "Score: 0.8519552946090698\n"
     ]
    }
   ],
   "source": [
    "beast_trial_ = tuner_11.oracle.get_best_trials()[0]\n",
    "beast_trial_.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model_5.predict(test)\n",
    "test_predictions = (test_predictions > 0.5).astype(int).flatten()\n",
    "# Prepare submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    \"PassengerId\": range(892, 892 + len(test_predictions)),\n",
    "    \"Survived\": test_predictions\n",
    "})\n",
    "\n",
    "# Save submission file\n",
    "submission_df.to_csv(\"submission_005_drop02_epo1000.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
